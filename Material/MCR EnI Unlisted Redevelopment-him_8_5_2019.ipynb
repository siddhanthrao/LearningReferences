{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user pyhive\n",
    "# !pip install --user thrift\n",
    "!pip install --user sasl\n",
    "# !pip install --user thrift_sasl\n",
    "# !pip install --user pycats\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import h2o\n",
    "\n",
    "import pyhive\n",
    "from pyhive import hive\n",
    "from datetime import datetime\n",
    "\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "import csv\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix ,classification_report,accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "from sklearn import model_selection, metrics   #Additional scklearn functions\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'usr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1082-4b6e9907edbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Place of Service Denial bucket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dbslp0525.uhc.com'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10002\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LDAP'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\"set mapreduce.job.queuename= araadh_q1.ararest_sq1\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstat1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\"select * from mcr_eni_unlist.pos_bucket_grouped_v2\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstat1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstat1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'usr' is not defined"
     ]
    }
   ],
   "source": [
    "#Place of Service Denial bucket\n",
    "conn = hive.connect(host='dbslp0525.uhc.com',port=10002,auth='LDAP',username=usr,password=pas)\n",
    "stat = \"\"\"set mapreduce.job.queuename= araadh_q1.ararest_sq1\"\"\"\n",
    "stat1=\"\"\"select * from mcr_eni_unlist.pos_bucket_grouped_v2\"\"\"\n",
    "stat1=stat1.replace(\"\\n\",\" \")\n",
    "stat1=stat1.replace('\\t',\" \")\n",
    "stat1=stat1.replace(\"   \",\" \")\n",
    "cur = conn.cursor()\n",
    "print(time.time())\n",
    "cur.execute(stat)\n",
    "cur.execute(stat1)\n",
    "print(time.time())\n",
    "pos_bucket_grouped= pd.DataFrame(cur.fetchall())\n",
    "pos_bucket_grouped.columns = ['plc_of_srvc','total_claim','apprvd_cases_count','denied_cases_count','prcrnt','pos_denied_prcnt_grp']\n",
    "print(\"done\")\n",
    "# Line of business Denial bucket\n",
    "\n",
    "conn = hive.connect(host='dbslp0525.uhc.com',port=10002,auth='LDAP',username=usr,password=pas)\n",
    "stat = \"\"\"set mapreduce.job.queuename= araadh_q1.ararest_sq1\"\"\"\n",
    "stat1=\"\"\"select * from mcr_eni_unlist.lob_bucket_grouped\"\"\"\n",
    "stat1=stat1.replace(\"\\n\",\" \")\n",
    "stat1=stat1.replace('\\t',\" \")\n",
    "stat1=stat1.replace(\"   \",\" \")\n",
    "cur = conn.cursor()\n",
    "print(time.time())\n",
    "cur.execute(stat)\n",
    "cur.execute(stat1)\n",
    "print(time.time())\n",
    "lob_bucket_grouped= pd.DataFrame(cur.fetchall())\n",
    "lob_bucket_grouped.columns = ['lob','total_claim','apprvd_cases_count','denied_cases_count','prcrnt','lob_denied_prcnt_grp']\n",
    "print(\"done\")\n",
    "\n",
    "conn = hive.connect(host='dbslp0525.uhc.com',port=10002,auth='LDAP',username=usr,password=pas)\n",
    "stat = \"\"\"set mapreduce.job.queuename= araadh_q1.ararest_sq1\"\"\"\n",
    "stat1=\"\"\"select * from mcr_eni_unlist.collect_set_bucket_grouped\"\"\"\n",
    "stat1=stat1.replace(\"\\n\",\" \")\n",
    "stat1=stat1.replace('\\t',\" \")\n",
    "stat1=stat1.replace(\"   \",\" \")\n",
    "cur = conn.cursor()\n",
    "print(time.time())\n",
    "cur.execute(stat)\n",
    "cur.execute(stat1)\n",
    "print(time.time())\n",
    "collect_set_bucket_grouped= pd.DataFrame(cur.fetchall())\n",
    "collect_set_bucket_grouped.columns = ['category_set','total_claim','apprvd_cases_count','denied_cases_count','prcrnt','collect_set_denied_prcnt_grp']\n",
    "print(\"done\")\n",
    "\n",
    "conn = hive.connect(host='dbslp0525.uhc.com',port=10002,auth='LDAP',username=usr,password=pas)\n",
    "stat = \"\"\"set mapreduce.job.queuename= araadh_q1.ararest_sq1\"\"\"\n",
    "stat1=\"\"\"select * from mcr_eni_unlist.cpt_bucket_grouped\"\"\"\n",
    "stat1=stat1.replace(\"\\n\",\" \")\n",
    "stat1=stat1.replace('\\t',\" \")\n",
    "stat1=stat1.replace(\"   \",\" \")\n",
    "cur = conn.cursor()\n",
    "print(time.time())\n",
    "cur.execute(stat)\n",
    "cur.execute(stat1)\n",
    "print(time.time())\n",
    "cpt_bucket_grouped= pd.DataFrame(cur.fetchall())\n",
    "cpt_bucket_grouped.columns = ['proc_cd_gal','total_services','apprvd_cases_count','denied_cases_count','prcrnt','cpt_denied_prcnt_grp']\n",
    "print(\"done\")\n",
    "\n",
    "conn = hive.connect(host='dbslp0525.uhc.com',port=10002,auth='LDAP',username=usr,password=pas)\n",
    "stat = \"\"\"set mapreduce.job.queuename= araadh_q1.ararest_sq1\"\"\"\n",
    "stat1=\"\"\"select * from mcr_eni_unlist.tin_bucket_grouped\"\"\"\n",
    "stat1=stat1.replace(\"\\n\",\" \")\n",
    "stat1=stat1.replace('\\t',\" \")\n",
    "stat1=stat1.replace(\"   \",\" \")\n",
    "cur = conn.cursor()\n",
    "print(time.time())\n",
    "cur.execute(stat)\n",
    "cur.execute(stat1)\n",
    "print(time.time())\n",
    "tin_bucket_grouped= pd.DataFrame(cur.fetchall())\n",
    "tin_bucket_grouped.columns = ['prov_tin','total_claim','apprvd_cases_count','denied_cases_count','prcrnt','tin_denied_prcnt_grp']\n",
    "print(\"done\")\n",
    "\n",
    "conn = hive.connect(host='dbslp0525.uhc.com',port=10002,auth='LDAP',username=usr,password=pas)\n",
    "stat = \"\"\"set mapreduce.job.queuename= araadh_q1.ararest_sq1\"\"\"\n",
    "stat1=\"\"\"select * from mcr_eni_unlist.state_bucket_grouped\"\"\"\n",
    "stat1=stat1.replace(\"\\n\",\" \")\n",
    "stat1=stat1.replace('\\t',\" \")\n",
    "stat1=stat1.replace(\"   \",\" \")\n",
    "cur = conn.cursor()\n",
    "print(time.time())\n",
    "cur.execute(stat)\n",
    "cur.execute(stat1)\n",
    "print(time.time())\n",
    "state_bucket_grouped= pd.DataFrame(cur.fetchall())\n",
    "state_bucket_grouped.columns = ['st_abbr_cd','total_claim','apprvd_cases_count','denied_cases_count','prcrnt','state_denied_prcnt_grp']\n",
    "print(\"done\")\n",
    "\n",
    "conn = hive.connect(host='dbslp0525.uhc.com',port=10002,auth='LDAP',username=usr,password=pas)\n",
    "stat = \"\"\"set mapreduce.job.queuename= araadh_q1.ararest_sq1\"\"\"\n",
    "stat1=\"\"\"select * from mcr_eni_unlist.diagnosis_bucket_grouped\"\"\"\n",
    "stat1=stat1.replace(\"\\n\",\" \")\n",
    "stat1=stat1.replace('\\t',\" \")\n",
    "stat1=stat1.replace(\"   \",\" \")\n",
    "cur = conn.cursor()\n",
    "print(time.time())\n",
    "cur.execute(stat)\n",
    "cur.execute(stat1)\n",
    "print(time.time())\n",
    "diagnosis_bucket_grouped= pd.DataFrame(cur.fetchall())\n",
    "diagnosis_bucket_grouped.columns = ['diag_3','total_claim','apprvd_cases_count','denied_cases_count','prcrnt','diag_denied_prcnt_grp']\n",
    "print(\"done\")\n",
    "\n",
    "conn = hive.connect(host='dbslp0525.uhc.com',port=10002,auth='LDAP',username=usr,password=pas)\n",
    "stat = \"\"\"set mapreduce.job.queuename= araadh_q1.ararest_sq1\"\"\"\n",
    "stat1=\"\"\"select * from mcr_eni_unlist.npi_bucket_grouped\"\"\"\n",
    "stat1=stat1.replace(\"\\n\",\" \")\n",
    "stat1=stat1.replace('\\t',\" \")\n",
    "stat1=stat1.replace(\"   \",\" \")\n",
    "cur = conn.cursor()\n",
    "print(time.time())\n",
    "cur.execute(stat)\n",
    "cur.execute(stat1)\n",
    "print(time.time())\n",
    "npi_bucket_grouped= pd.DataFrame(cur.fetchall())\n",
    "npi_bucket_grouped.columns = ['npi','total_claim','apprvd_cases_count','denied_cases_count','prcrnt','npi_denied_prcnt_grp']\n",
    "print(\"done\")\n",
    "\n",
    "conn = hive.connect(host='dbslp0525.uhc.com',port=10002,auth='LDAP',username=usr,password=pas)\n",
    "stat = \"\"\"set mapreduce.job.queuename= araadh_q1.ararest_sq1\"\"\"\n",
    "stat1=\"\"\"select * from mcr_eni_unlist.month_bucket_grouped\"\"\"\n",
    "stat1=stat1.replace(\"\\n\",\" \")\n",
    "stat1=stat1.replace('\\t',\" \")\n",
    "stat1=stat1.replace(\"   \",\" \")\n",
    "cur = conn.cursor()\n",
    "print(time.time())\n",
    "cur.execute(stat)\n",
    "cur.execute(stat1)\n",
    "print(time.time())\n",
    "month_bucket_grouped= pd.DataFrame(cur.fetchall())\n",
    "month_bucket_grouped.columns = ['bil_recv_month','total_claim','apprvd_cases_count','denied_cases_count','prcrnt','month_denied_prcnt_grp']\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_bucket_grouped.to_pickle('/mapr/datalake/uhc/ei/pi_ara/beta/projects/G12/MCR_EnI/pickle_files/pos_bucket_grouped.pkl')\n",
    "lob_bucket_grouped.to_pickle('/mapr/datalake/uhc/ei/pi_ara/beta/projects/G12/MCR_EnI/pickle_files/lob_bucket_grouped.pkl')\n",
    "collect_set_bucket_grouped.to_pickle('/mapr/datalake/uhc/ei/pi_ara/beta/projects/G12/MCR_EnI/pickle_files/collect_set_bucket_grouped.pkl')\n",
    "cpt_bucket_grouped.to_pickle('/mapr/datalake/uhc/ei/pi_ara/beta/projects/G12/MCR_EnI/pickle_files/cpt_bucket_grouped.pkl')\n",
    "policy_bucket_grouped.to_pickle('/mapr/datalake/uhc/ei/pi_ara/beta/projects/G12/MCR_EnI/pickle_files/policy_bucket_grouped.pkl')\n",
    "tin_bucket_grouped.to_pickle('/mapr/datalake/uhc/ei/pi_ara/beta/projects/G12/MCR_EnI/pickle_files/tin_bucket_grouped.pkl')\n",
    "state_bucket_grouped.to_pickle('/mapr/datalake/uhc/ei/pi_ara/beta/projects/G12/MCR_EnI/pickle_files/state_bucket_grouped.pkl')\n",
    "diagnosis_bucket_grouped.to_pickle('/mapr/datalake/uhc/ei/pi_ara/beta/projects/G12/MCR_EnI/pickle_files/diagnosis_bucket_grouped.pkl')\n",
    "npi_bucket_grouped.to_pickle('/mapr/datalake/uhc/ei/pi_ara/beta/projects/G12/MCR_EnI/pickle_files/npi_bucket_grouped.pkl')\n",
    "month_bucket_grouped.to_pickle('/mapr/datalake/uhc/ei/pi_ara/beta/projects/G12/MCR_EnI/pickle_files/month_bucket_grouped.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = hive.connect(host='dbslp0525.uhc.com',port=10002,auth='LDAP',username=usr,password=pas)\n",
    "stat = \"\"\"set mapreduce.job.queuename= araadh_q1.ararest_sq1\"\"\"\n",
    "stat1=\"\"\"select * from mcr_eni_unlist.inscope_inclu_train\"\"\"\n",
    "stat1=stat1.replace(\"\\n\",\" \")\n",
    "stat1=stat1.replace('\\t',\" \")\n",
    "stat1=stat1.replace(\"   \",\" \")\n",
    "cur = conn.cursor()\n",
    "print(time.time())\n",
    "cur.execute(stat)\n",
    "cur.execute(stat1)\n",
    "print(time.time())\n",
    "inscope_inclu_train= pd.DataFrame(cur.fetchall())\n",
    "inscope_inclu_train.columns = ['key','icn','bil_recv_dt','policy','report_date','ufe_claim_id','fst_srvc_dt','proc_cd_gal','prov_tin','lin_chrg_amt','bth_dt','st_abbr_cd','diag_cd','npi','clm_tot_chrg_amt','dmg_pat_sex','lob','units','plc_of_srvc','proc_sub_cat','unlisted_flag','srvc_den_flag','fk_flag','clm_den_flag','clm_tot_chrg_amt_v2','rw_nm','diag_3','category_set','mem_age','listed_presence','unit_agg']\n",
    "print(\"done\")\n",
    "inscope_inclu_train.to_pickle('/mapr/datalake/uhc/ei/pi_ara/beta/projects/G12/MCR_EnI/pickle_files/inscope_inclu_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = hive.connect(host='dbslp0525.uhc.com',port=10002,auth='LDAP',username=usr,password=pas)\n",
    "stat = \"\"\"set mapreduce.job.queuename= araadh_q1.ararest_sq1\"\"\"\n",
    "stat1=\"\"\"select * from mcr_eni_unlist.inscope_inclu_oos\"\"\"\n",
    "stat1=stat1.replace(\"\\n\",\" \")\n",
    "stat1=stat1.replace('\\t',\" \")\n",
    "stat1=stat1.replace(\"   \",\" \")\n",
    "cur = conn.cursor()\n",
    "print(time.time())\n",
    "cur.execute(stat)\n",
    "cur.execute(stat1)\n",
    "print(time.time())\n",
    "inscope_inclu_oos= pd.DataFrame(cur.fetchall())\n",
    "inscope_inclu_oos.columns = ['key','icn','bil_recv_dt','policy','report_date','ufe_claim_id','fst_srvc_dt','proc_cd_gal','prov_tin','lin_chrg_amt','bth_dt','st_abbr_cd','diag_cd','npi','clm_tot_chrg_amt','dmg_pat_sex','lob','units','plc_of_srvc','proc_sub_cat','unlisted_flag','srvc_den_flag','fk_flag','clm_den_flag','clm_tot_chrg_amt_v2','rw_nm','diag_3','category_set','mem_age','listed_presence','unit_agg']\n",
    "print(\"done\")\n",
    "inscope_inclu_oos.to_pickle('/mapr/datalake/uhc/ei/pi_ara/beta/projects/G12/MCR_EnI/pickle_files/inscope_inclu_oos.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "inscope_inclu_train = pd.read_pickle('/projects/G12/pickle_data/inscope_inclu_train.pkl')\n",
    "inscope_inclu_oos = pd.read_pickle('/projects/G12/pickle_data/inscope_inclu_oos.pkl')\n",
    "\n",
    "pos_bucket_grouped = pd.read_pickle('/projects/G12/pickle_data/pos_bucket_grouped.pkl')\n",
    "lob_bucket_grouped = pd.read_pickle('/projects/G12/pickle_data/lob_bucket_grouped.pkl')\n",
    "collect_set_bucket_grouped = pd.read_pickle('/projects/G12/pickle_data/collect_set_bucket_grouped.pkl')\n",
    "cpt_bucket_grouped = pd.read_pickle('/projects/G12/pickle_data/cpt_bucket_grouped.pkl')\n",
    "policy_bucket_grouped = pd.read_pickle('/projects/G12/pickle_data/policy_bucket_grouped.pkl')\n",
    "tin_bucket_grouped = pd.read_pickle('/projects/G12/pickle_data/tin_bucket_grouped.pkl')\n",
    "state_bucket_grouped = pd.read_pickle('/projects/G12/pickle_data/state_bucket_grouped.pkl')\n",
    "diagnosis_bucket_grouped = pd.read_pickle('/projects/G12/pickle_data/diagnosis_bucket_grouped.pkl')\n",
    "npi_bucket_grouped = pd.read_pickle('/projects/G12/pickle_data/npi_bucket_grouped.pkl')\n",
    "month_bucket_grouped = pd.read_pickle('/projects/G12/pickle_data/month_bucket_grouped.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "inscope_inclu_train = pd.read_pickle('/projects/G12/pickle_data/inscope_inclu_train.pkl')\n",
    "inscope_inclu_oos = pd.read_pickle('/projects/G12/pickle_data/inscope_inclu_oos.pkl')\n",
    "\n",
    "pos_bucket_grouped_v2 = pd.read_pickle('/projects/G12/pickle_data/pos_bucket_grouped_v2.pkl')\n",
    "lob_bucket_grouped_v2 = pd.read_pickle('/projects/G12/pickle_data/lob_bucket_grouped_v2.pkl')\n",
    "collect_set_bucket_grouped_v2 = pd.read_pickle('/projects/G12/pickle_data/collect_set_bucket_grouped_v2.pkl')\n",
    "cpt_bucket_grouped_v2 = pd.read_pickle('/projects/G12/pickle_data/cpt_bucket_grouped_v2.pkl')\n",
    "policy_bucket_grouped_v2 = pd.read_pickle('/projects/G12/pickle_data/policy_bucket_grouped_v2.pkl')\n",
    "tin_bucket_grouped_v2 = pd.read_pickle('/projects/G12/pickle_data/tin_bucket_grouped_v2.pkl')\n",
    "state_bucket_grouped_v2 = pd.read_pickle('/projects/G12/pickle_data/state_bucket_grouped_v2.pkl')\n",
    "diagnosis_bucket_grouped_v2 = pd.read_pickle('/projects/G12/pickle_data/diagnosis_bucket_grouped_v2.pkl')\n",
    "npi_bucket_grouped_v2 = pd.read_pickle('/projects/G12/pickle_data/npi_bucket_grouped_v2.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = inscope_inclu_train.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = inscope_inclu_oos.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obj = train.select_dtypes(['object'])\n",
    "train[df_obj.columns] = df_obj.apply(lambda x: x.str.strip().str.upper()).replace('', np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obj = test.select_dtypes(['object'])\n",
    "test[df_obj.columns] = df_obj.apply(lambda x: x.str.strip().str.upper()).replace('', np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cat = train.select_dtypes(['object']).columns\n",
    "cols_cont = train.select_dtypes(['float','int']).columns\n",
    "\n",
    "train[cols_cat]=train[cols_cat].fillna(train[cols_cat].mode().iloc[0])\n",
    "train[cols_cont]=train[cols_cont].fillna(train[cols_cont].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cat = test.select_dtypes(['object']).columns\n",
    "cols_cont = test.select_dtypes(['float','int']).columns\n",
    "\n",
    "test[cols_cat]=test[cols_cat].fillna(train[cols_cat].mode().iloc[0])\n",
    "test[cols_cont]=test[cols_cont].fillna(train[cols_cont].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['lin_chrg_amt_norm']=(train['lin_chrg_amt']-train['lin_chrg_amt'].min())/(train['lin_chrg_amt'].max()-train['lin_chrg_amt'].min())\n",
    "train['clm_tot_chrg_amt_v2_norm']=(train['clm_tot_chrg_amt_v2']-train['clm_tot_chrg_amt_v2'].min())/(train['clm_tot_chrg_amt_v2'].max()-train['clm_tot_chrg_amt_v2'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['lin_chrg_amt_norm']=(test['lin_chrg_amt']-train['lin_chrg_amt'].min())/(train['lin_chrg_amt'].max()-train['lin_chrg_amt'].min())\n",
    "test['clm_tot_chrg_amt_v2_norm']=(test['clm_tot_chrg_amt_v2']-train['clm_tot_chrg_amt_v2'].min())/(train['clm_tot_chrg_amt_v2'].max()-train['clm_tot_chrg_amt_v2'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['lin_chrg_amt_norm_log'] = np.log(train['lin_chrg_amt_norm']+1)\n",
    "train['clm_tot_chrg_amt_v2_norm_log'] = np.log(train['clm_tot_chrg_amt_v2_norm']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['lin_chrg_amt_norm_log'] = np.log(test['lin_chrg_amt_norm']+1)\n",
    "test['clm_tot_chrg_amt_v2_norm_log'] = np.log(test['clm_tot_chrg_amt_v2_norm']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin1 = [train['mem_age'].min()-1,20,45,60,train['mem_age'].max()+1]\n",
    "train['mem_age_bin'] = pd.cut(train['mem_age'], bin1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin1 = [train['mem_age'].min()-1,20,45,60,train['mem_age'].max()+1]\n",
    "test['mem_age_bin'] = pd.cut(test['mem_age'], bin1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['dmg_pat_sex']=np.where(train['dmg_pat_sex']=='F',0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['dmg_pat_sex']=np.where(test['dmg_pat_sex']=='F',0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['bil_recv_dt']=pd.to_datetime(train['bil_recv_dt'], format = \"%Y-%m-%d\")\n",
    "train['bil_recv_month'] = train['bil_recv_dt'].apply(lambda x: x.month)\n",
    "train['bil_recv_month'] = train['bil_recv_month'].astype(str)\n",
    "# month_bucket_grouped['bil_recv_month'] = month_bucket_grouped['bil_recv_month'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['bil_recv_dt']=pd.to_datetime(test['bil_recv_dt'], format = \"%Y-%m-%d\")\n",
    "test['bil_recv_month'] = test['bil_recv_dt'].apply(lambda x: x.month)\n",
    "test['bil_recv_month'] = test['bil_recv_month'].astype(str)\n",
    "# month_bucket_grouped['bil_recv_month'] = month_bucket_grouped['bil_recv_month'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['fst_srvc_dt']=pd.to_datetime(train['fst_srvc_dt'], format = \"%Y-%m-%d\")\n",
    "data_icn_fst_min=train.groupby(['icn'],as_index=False)['fst_srvc_dt'].min()\n",
    "data_icn_fst_min['fst_srvc_dt_min']=data_icn_fst_min['fst_srvc_dt']\n",
    "data_icn_fst_min=data_icn_fst_min.drop(['fst_srvc_dt'],axis=1)\n",
    "data_icn_fst_max=train.groupby(['icn'],as_index=False)['fst_srvc_dt'].max()\n",
    "data_icn_fst_max['fst_srvc_dt_max']=data_icn_fst_max['fst_srvc_dt']\n",
    "data_icn_fst_max=data_icn_fst_max.drop(['fst_srvc_dt'],axis=1)\n",
    "\n",
    "train=pd.merge(pd.merge(train,data_icn_fst_min,on='icn',how='left'),data_icn_fst_max,on='icn',how='left')\n",
    "\n",
    "train['bil_diff_fst']=train['bil_recv_dt']-train['fst_srvc_dt_min']\n",
    "train['fst_max_min']=train['fst_srvc_dt_max']-train['fst_srvc_dt_min']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['fst_srvc_dt']=pd.to_datetime(test['fst_srvc_dt'], format = \"%Y-%m-%d\")\n",
    "data_icn_fst_min=test.groupby(['icn'],as_index=False)['fst_srvc_dt'].min()\n",
    "data_icn_fst_min['fst_srvc_dt_min']=data_icn_fst_min['fst_srvc_dt']\n",
    "data_icn_fst_min=data_icn_fst_min.drop(['fst_srvc_dt'],axis=1)\n",
    "data_icn_fst_max=test.groupby(['icn'],as_index=False)['fst_srvc_dt'].max()\n",
    "data_icn_fst_max['fst_srvc_dt_max']=data_icn_fst_max['fst_srvc_dt']\n",
    "data_icn_fst_max=data_icn_fst_max.drop(['fst_srvc_dt'],axis=1)\n",
    "\n",
    "test=pd.merge(pd.merge(test,data_icn_fst_min,on='icn',how='left'),data_icn_fst_max,on='icn',how='left')\n",
    "\n",
    "test['bil_diff_fst']=test['bil_recv_dt']-test['fst_srvc_dt_min']\n",
    "test['fst_max_min']=test['fst_srvc_dt_max']-test['fst_srvc_dt_min']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['bil_diff_fst']=train['bil_diff_fst'].astype('timedelta64[D]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['bil_diff_fst']=test['bil_diff_fst'].astype('timedelta64[D]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['fst_max_min']=train['fst_max_min'].astype('timedelta64[D]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['fst_max_min']=test['fst_max_min'].astype('timedelta64[D]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['bil_diff_fst_norm']=(train['bil_diff_fst']-train['bil_diff_fst'].min())/(train['bil_diff_fst'].max()-train['bil_diff_fst'].min())\n",
    "train['fst_max_min_norm']=(train['fst_max_min']-train['fst_max_min'].min())/(train['fst_max_min'].max()-train['fst_max_min'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['bil_diff_fst_norm']=(test['bil_diff_fst']-train['bil_diff_fst'].min())/(train['bil_diff_fst'].max()-train['bil_diff_fst'].min())\n",
    "test['fst_max_min_norm']=(test['fst_max_min']-train['fst_max_min'].min())/(train['fst_max_min'].max()-train['fst_max_min'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['bil_diff_fst_norm_log'] = np.log(train['bil_diff_fst_norm']+1)\n",
    "train['fst_max_min_norm_log'] = np.log(train['fst_max_min_norm']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['bil_diff_fst_norm_log'] = np.log(test['bil_diff_fst_norm']+1)\n",
    "test['fst_max_min_norm_log'] = np.log(test['fst_max_min_norm']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>icn</th>\n",
       "      <th>bil_recv_dt</th>\n",
       "      <th>policy</th>\n",
       "      <th>report_date</th>\n",
       "      <th>ufe_claim_id</th>\n",
       "      <th>fst_srvc_dt</th>\n",
       "      <th>proc_cd_gal</th>\n",
       "      <th>prov_tin</th>\n",
       "      <th>lin_chrg_amt</th>\n",
       "      <th>...</th>\n",
       "      <th>mem_age_bin</th>\n",
       "      <th>bil_recv_month</th>\n",
       "      <th>fst_srvc_dt_min</th>\n",
       "      <th>fst_srvc_dt_max</th>\n",
       "      <th>bil_diff_fst</th>\n",
       "      <th>fst_max_min</th>\n",
       "      <th>bil_diff_fst_norm</th>\n",
       "      <th>fst_max_min_norm</th>\n",
       "      <th>bil_diff_fst_norm_log</th>\n",
       "      <th>fst_max_min_norm_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3340484014-28289-2018-03-30-1531.85</td>\n",
       "      <td>3340484014</td>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>912796</td>\n",
       "      <td>2018-04-03</td>\n",
       "      <td>994180921159100</td>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>28289</td>\n",
       "      <td>561079264</td>\n",
       "      <td>1531.85</td>\n",
       "      <td>...</td>\n",
       "      <td>(45.0, 60.0]</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018859</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3340484014-28899-2018-03-30-2779.0</td>\n",
       "      <td>3340484014</td>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>912796</td>\n",
       "      <td>2018-04-03</td>\n",
       "      <td>994180921159100</td>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>28899</td>\n",
       "      <td>561079264</td>\n",
       "      <td>2779.00</td>\n",
       "      <td>...</td>\n",
       "      <td>(45.0, 60.0]</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018859</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3340992779-43774-2018-03-27-2992.0</td>\n",
       "      <td>3340992779</td>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>717473</td>\n",
       "      <td>2018-04-03</td>\n",
       "      <td>994180922143200</td>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>43774</td>\n",
       "      <td>593366100</td>\n",
       "      <td>2992.00</td>\n",
       "      <td>...</td>\n",
       "      <td>(45.0, 60.0]</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021805</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3340992779-47379-2018-03-27-2603.0</td>\n",
       "      <td>3340992779</td>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>717473</td>\n",
       "      <td>2018-04-03</td>\n",
       "      <td>994180922143200</td>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>47379</td>\n",
       "      <td>593366100</td>\n",
       "      <td>2603.00</td>\n",
       "      <td>...</td>\n",
       "      <td>(45.0, 60.0]</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021805</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3341042986-43235-2018-01-10-750.0</td>\n",
       "      <td>3341042986</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>907816</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>994180941039400</td>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>43235</td>\n",
       "      <td>760204325</td>\n",
       "      <td>750.00</td>\n",
       "      <td>...</td>\n",
       "      <td>(20.0, 45.0]</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095492</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   key         icn bil_recv_dt  policy  \\\n",
       "0  3340484014-28289-2018-03-30-1531.85  3340484014  2018-04-02  912796   \n",
       "1   3340484014-28899-2018-03-30-2779.0  3340484014  2018-04-02  912796   \n",
       "2   3340992779-43774-2018-03-27-2992.0  3340992779  2018-04-02  717473   \n",
       "3   3340992779-47379-2018-03-27-2603.0  3340992779  2018-04-02  717473   \n",
       "4    3341042986-43235-2018-01-10-750.0  3341042986  2018-04-04  907816   \n",
       "\n",
       "  report_date     ufe_claim_id fst_srvc_dt proc_cd_gal   prov_tin  \\\n",
       "0  2018-04-03  994180921159100  2018-03-30       28289  561079264   \n",
       "1  2018-04-03  994180921159100  2018-03-30       28899  561079264   \n",
       "2  2018-04-03  994180922143200  2018-03-27       43774  593366100   \n",
       "3  2018-04-03  994180922143200  2018-03-27       47379  593366100   \n",
       "4  2018-04-05  994180941039400  2018-01-10       43235  760204325   \n",
       "\n",
       "   lin_chrg_amt  ...   mem_age_bin bil_recv_month fst_srvc_dt_min  \\\n",
       "0       1531.85  ...  (45.0, 60.0]              4      2018-03-30   \n",
       "1       2779.00  ...  (45.0, 60.0]              4      2018-03-30   \n",
       "2       2992.00  ...  (45.0, 60.0]              4      2018-03-27   \n",
       "3       2603.00  ...  (45.0, 60.0]              4      2018-03-27   \n",
       "4        750.00  ...  (20.0, 45.0]              4      2018-01-10   \n",
       "\n",
       "  fst_srvc_dt_max  bil_diff_fst  fst_max_min bil_diff_fst_norm  \\\n",
       "0      2018-03-30           3.0          0.0          0.019038   \n",
       "1      2018-03-30           3.0          0.0          0.019038   \n",
       "2      2018-03-27           6.0          0.0          0.022044   \n",
       "3      2018-03-27           6.0          0.0          0.022044   \n",
       "4      2018-01-10          84.0          0.0          0.100200   \n",
       "\n",
       "   fst_max_min_norm bil_diff_fst_norm_log fst_max_min_norm_log  \n",
       "0               0.0              0.018859                  0.0  \n",
       "1               0.0              0.018859                  0.0  \n",
       "2               0.0              0.021805                  0.0  \n",
       "3               0.0              0.021805                  0.0  \n",
       "4               0.0              0.095492                  0.0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>icn</th>\n",
       "      <th>bil_recv_dt</th>\n",
       "      <th>policy</th>\n",
       "      <th>report_date</th>\n",
       "      <th>ufe_claim_id</th>\n",
       "      <th>fst_srvc_dt</th>\n",
       "      <th>proc_cd_gal</th>\n",
       "      <th>prov_tin</th>\n",
       "      <th>lin_chrg_amt</th>\n",
       "      <th>...</th>\n",
       "      <th>mem_age_bin</th>\n",
       "      <th>bil_recv_month</th>\n",
       "      <th>fst_srvc_dt_min</th>\n",
       "      <th>fst_srvc_dt_max</th>\n",
       "      <th>bil_diff_fst</th>\n",
       "      <th>fst_max_min</th>\n",
       "      <th>bil_diff_fst_norm</th>\n",
       "      <th>fst_max_min_norm</th>\n",
       "      <th>bil_diff_fst_norm_log</th>\n",
       "      <th>fst_max_min_norm_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7576799270-95870-2018-07-09-7956.0</td>\n",
       "      <td>7576799270</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>729433</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>910183615240300</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>95870</td>\n",
       "      <td>821548769</td>\n",
       "      <td>7956.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(45.0, 60.0]</td>\n",
       "      <td>12</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171745</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7576799270-95938-2018-07-09-4501.0</td>\n",
       "      <td>7576799270</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>729433</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>910183615240300</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>95938</td>\n",
       "      <td>821548769</td>\n",
       "      <td>4501.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(45.0, 60.0]</td>\n",
       "      <td>12</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171745</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7576799270-95955-2018-07-09-7500.0</td>\n",
       "      <td>7576799270</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>729433</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>910183615240300</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>95955</td>\n",
       "      <td>821548769</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(45.0, 60.0]</td>\n",
       "      <td>12</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171745</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7576799270-95999-2018-07-09-7500.0</td>\n",
       "      <td>7576799270</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>729433</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>910183615240300</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>95999</td>\n",
       "      <td>821548769</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(45.0, 60.0]</td>\n",
       "      <td>12</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171745</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7576799270-G0453-2018-07-09-30000.0</td>\n",
       "      <td>7576799270</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>729433</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>910183615240300</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>G0453</td>\n",
       "      <td>821548769</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(45.0, 60.0]</td>\n",
       "      <td>12</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171745</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   key         icn bil_recv_dt  policy  \\\n",
       "0   7576799270-95870-2018-07-09-7956.0  7576799270  2018-12-27  729433   \n",
       "1   7576799270-95938-2018-07-09-4501.0  7576799270  2018-12-27  729433   \n",
       "2   7576799270-95955-2018-07-09-7500.0  7576799270  2018-12-27  729433   \n",
       "3   7576799270-95999-2018-07-09-7500.0  7576799270  2018-12-27  729433   \n",
       "4  7576799270-G0453-2018-07-09-30000.0  7576799270  2018-12-27  729433   \n",
       "\n",
       "  report_date     ufe_claim_id fst_srvc_dt proc_cd_gal   prov_tin  \\\n",
       "0  2019-04-01  910183615240300  2018-07-09       95870  821548769   \n",
       "1  2019-04-01  910183615240300  2018-07-09       95938  821548769   \n",
       "2  2019-04-01  910183615240300  2018-07-09       95955  821548769   \n",
       "3  2019-04-01  910183615240300  2018-07-09       95999  821548769   \n",
       "4  2019-04-01  910183615240300  2018-07-09       G0453  821548769   \n",
       "\n",
       "   lin_chrg_amt  ...   mem_age_bin bil_recv_month fst_srvc_dt_min  \\\n",
       "0        7956.0  ...  (45.0, 60.0]             12      2018-07-09   \n",
       "1        4501.0  ...  (45.0, 60.0]             12      2018-07-09   \n",
       "2        7500.0  ...  (45.0, 60.0]             12      2018-07-09   \n",
       "3        7500.0  ...  (45.0, 60.0]             12      2018-07-09   \n",
       "4       30000.0  ...  (45.0, 60.0]             12      2018-07-09   \n",
       "\n",
       "  fst_srvc_dt_max  bil_diff_fst  fst_max_min bil_diff_fst_norm  \\\n",
       "0      2018-07-09         171.0          0.0          0.187375   \n",
       "1      2018-07-09         171.0          0.0          0.187375   \n",
       "2      2018-07-09         171.0          0.0          0.187375   \n",
       "3      2018-07-09         171.0          0.0          0.187375   \n",
       "4      2018-07-09         171.0          0.0          0.187375   \n",
       "\n",
       "   fst_max_min_norm bil_diff_fst_norm_log fst_max_min_norm_log  \n",
       "0               0.0              0.171745                  0.0  \n",
       "1               0.0              0.171745                  0.0  \n",
       "2               0.0              0.171745                  0.0  \n",
       "3               0.0              0.171745                  0.0  \n",
       "4               0.0              0.171745                  0.0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_average=train.groupby(['diag_cd'],as_index=False)['clm_tot_chrg_amt_v2_norm_log'].mean()\n",
    "diag_average['diag_amnt_avg']=diag_average['clm_tot_chrg_amt_v2_norm_log']\n",
    "diag_average=diag_average.drop(['clm_tot_chrg_amt_v2_norm_log'],axis=1)\n",
    "diag_average.head()\n",
    "\n",
    "tin_diag_average=train.groupby(['prov_tin','diag_cd'],as_index=False)['clm_tot_chrg_amt_v2_norm_log'].mean()\n",
    "tin_diag_average['tin_diag_amnt_avg']=tin_diag_average['clm_tot_chrg_amt_v2_norm_log']\n",
    "tin_diag_average=tin_diag_average.drop(['clm_tot_chrg_amt_v2_norm_log'],axis=1)\n",
    "\n",
    "npi_diag_average=train.groupby(['npi','diag_cd'],as_index=False)['clm_tot_chrg_amt_v2_norm_log'].mean()\n",
    "npi_diag_average['npi_diag_amnt_avg']=npi_diag_average['clm_tot_chrg_amt_v2_norm_log']\n",
    "npi_diag_average=npi_diag_average.drop(['clm_tot_chrg_amt_v2_norm_log'],axis=1)\n",
    "\n",
    "\n",
    "train=pd.merge(pd.merge(pd.merge(train,diag_average,on='diag_cd',how='left'),tin_diag_average,on=['prov_tin','diag_cd'],how='left'),\n",
    "               npi_diag_average,on=['npi','diag_cd'],how='left')\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_average=test.groupby(['diag_cd'],as_index=False)['clm_tot_chrg_amt_v2_norm_log'].mean()\n",
    "diag_average['diag_amnt_avg']=diag_average['clm_tot_chrg_amt_v2_norm_log']\n",
    "diag_average=diag_average.drop(['clm_tot_chrg_amt_v2_norm_log'],axis=1)\n",
    "diag_average.head()\n",
    "\n",
    "tin_diag_average=test.groupby(['prov_tin','diag_cd'],as_index=False)['clm_tot_chrg_amt_v2_norm_log'].mean()\n",
    "tin_diag_average['tin_diag_amnt_avg']=tin_diag_average['clm_tot_chrg_amt_v2_norm_log']\n",
    "tin_diag_average=tin_diag_average.drop(['clm_tot_chrg_amt_v2_norm_log'],axis=1)\n",
    "\n",
    "npi_diag_average=test.groupby(['npi','diag_cd'],as_index=False)['clm_tot_chrg_amt_v2_norm_log'].mean()\n",
    "npi_diag_average['npi_diag_amnt_avg']=npi_diag_average['clm_tot_chrg_amt_v2_norm_log']\n",
    "npi_diag_average=npi_diag_average.drop(['clm_tot_chrg_amt_v2_norm_log'],axis=1)\n",
    "\n",
    "\n",
    "test=pd.merge(pd.merge(pd.merge(test,diag_average,on='diag_cd',how='left'),tin_diag_average,on=['prov_tin','diag_cd'],how='left'),\n",
    "               npi_diag_average,on=['npi','diag_cd'],how='left')\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>icn</th>\n",
       "      <th>bil_recv_dt</th>\n",
       "      <th>policy</th>\n",
       "      <th>report_date</th>\n",
       "      <th>ufe_claim_id</th>\n",
       "      <th>fst_srvc_dt</th>\n",
       "      <th>proc_cd_gal</th>\n",
       "      <th>prov_tin</th>\n",
       "      <th>lin_chrg_amt</th>\n",
       "      <th>...</th>\n",
       "      <th>fst_srvc_dt_max</th>\n",
       "      <th>bil_diff_fst</th>\n",
       "      <th>fst_max_min</th>\n",
       "      <th>bil_diff_fst_norm</th>\n",
       "      <th>fst_max_min_norm</th>\n",
       "      <th>bil_diff_fst_norm_log</th>\n",
       "      <th>fst_max_min_norm_log</th>\n",
       "      <th>diag_amnt_avg</th>\n",
       "      <th>tin_diag_amnt_avg</th>\n",
       "      <th>npi_diag_amnt_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3340484014-28289-2018-03-30-1531.85</td>\n",
       "      <td>3340484014</td>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>912796</td>\n",
       "      <td>2018-04-03</td>\n",
       "      <td>994180921159100</td>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>28289</td>\n",
       "      <td>561079264</td>\n",
       "      <td>1531.85</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014894</td>\n",
       "      <td>0.009718</td>\n",
       "      <td>0.009718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3340484014-28899-2018-03-30-2779.0</td>\n",
       "      <td>3340484014</td>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>912796</td>\n",
       "      <td>2018-04-03</td>\n",
       "      <td>994180921159100</td>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>28899</td>\n",
       "      <td>561079264</td>\n",
       "      <td>2779.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014894</td>\n",
       "      <td>0.009718</td>\n",
       "      <td>0.009718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3340992779-43774-2018-03-27-2992.0</td>\n",
       "      <td>3340992779</td>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>717473</td>\n",
       "      <td>2018-04-03</td>\n",
       "      <td>994180922143200</td>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>43774</td>\n",
       "      <td>593366100</td>\n",
       "      <td>2992.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028265</td>\n",
       "      <td>0.012722</td>\n",
       "      <td>0.012722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3340992779-47379-2018-03-27-2603.0</td>\n",
       "      <td>3340992779</td>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>717473</td>\n",
       "      <td>2018-04-03</td>\n",
       "      <td>994180922143200</td>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>47379</td>\n",
       "      <td>593366100</td>\n",
       "      <td>2603.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028265</td>\n",
       "      <td>0.012722</td>\n",
       "      <td>0.012722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3341042986-43235-2018-01-10-750.0</td>\n",
       "      <td>3341042986</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>907816</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>994180941039400</td>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>43235</td>\n",
       "      <td>760204325</td>\n",
       "      <td>750.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025261</td>\n",
       "      <td>0.040946</td>\n",
       "      <td>0.040946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   key         icn bil_recv_dt  policy  \\\n",
       "0  3340484014-28289-2018-03-30-1531.85  3340484014  2018-04-02  912796   \n",
       "1   3340484014-28899-2018-03-30-2779.0  3340484014  2018-04-02  912796   \n",
       "2   3340992779-43774-2018-03-27-2992.0  3340992779  2018-04-02  717473   \n",
       "3   3340992779-47379-2018-03-27-2603.0  3340992779  2018-04-02  717473   \n",
       "4    3341042986-43235-2018-01-10-750.0  3341042986  2018-04-04  907816   \n",
       "\n",
       "  report_date     ufe_claim_id fst_srvc_dt proc_cd_gal   prov_tin  \\\n",
       "0  2018-04-03  994180921159100  2018-03-30       28289  561079264   \n",
       "1  2018-04-03  994180921159100  2018-03-30       28899  561079264   \n",
       "2  2018-04-03  994180922143200  2018-03-27       43774  593366100   \n",
       "3  2018-04-03  994180922143200  2018-03-27       47379  593366100   \n",
       "4  2018-04-05  994180941039400  2018-01-10       43235  760204325   \n",
       "\n",
       "   lin_chrg_amt  ... fst_srvc_dt_max bil_diff_fst fst_max_min  \\\n",
       "0       1531.85  ...      2018-03-30          3.0         0.0   \n",
       "1       2779.00  ...      2018-03-30          3.0         0.0   \n",
       "2       2992.00  ...      2018-03-27          6.0         0.0   \n",
       "3       2603.00  ...      2018-03-27          6.0         0.0   \n",
       "4        750.00  ...      2018-01-10         84.0         0.0   \n",
       "\n",
       "  bil_diff_fst_norm  fst_max_min_norm  bil_diff_fst_norm_log  \\\n",
       "0          0.019038               0.0               0.018859   \n",
       "1          0.019038               0.0               0.018859   \n",
       "2          0.022044               0.0               0.021805   \n",
       "3          0.022044               0.0               0.021805   \n",
       "4          0.100200               0.0               0.095492   \n",
       "\n",
       "  fst_max_min_norm_log  diag_amnt_avg tin_diag_amnt_avg npi_diag_amnt_avg  \n",
       "0                  0.0       0.014894          0.009718          0.009718  \n",
       "1                  0.0       0.014894          0.009718          0.009718  \n",
       "2                  0.0       0.028265          0.012722          0.012722  \n",
       "3                  0.0       0.028265          0.012722          0.012722  \n",
       "4                  0.0       0.025261          0.040946          0.040946  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>icn</th>\n",
       "      <th>bil_recv_dt</th>\n",
       "      <th>policy</th>\n",
       "      <th>report_date</th>\n",
       "      <th>ufe_claim_id</th>\n",
       "      <th>fst_srvc_dt</th>\n",
       "      <th>proc_cd_gal</th>\n",
       "      <th>prov_tin</th>\n",
       "      <th>lin_chrg_amt</th>\n",
       "      <th>...</th>\n",
       "      <th>fst_srvc_dt_max</th>\n",
       "      <th>bil_diff_fst</th>\n",
       "      <th>fst_max_min</th>\n",
       "      <th>bil_diff_fst_norm</th>\n",
       "      <th>fst_max_min_norm</th>\n",
       "      <th>bil_diff_fst_norm_log</th>\n",
       "      <th>fst_max_min_norm_log</th>\n",
       "      <th>diag_amnt_avg</th>\n",
       "      <th>tin_diag_amnt_avg</th>\n",
       "      <th>npi_diag_amnt_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7576799270-95870-2018-07-09-7956.0</td>\n",
       "      <td>7576799270</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>729433</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>910183615240300</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>95870</td>\n",
       "      <td>821548769</td>\n",
       "      <td>7956.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106392</td>\n",
       "      <td>0.12707</td>\n",
       "      <td>0.12707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7576799270-95938-2018-07-09-4501.0</td>\n",
       "      <td>7576799270</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>729433</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>910183615240300</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>95938</td>\n",
       "      <td>821548769</td>\n",
       "      <td>4501.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106392</td>\n",
       "      <td>0.12707</td>\n",
       "      <td>0.12707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7576799270-95955-2018-07-09-7500.0</td>\n",
       "      <td>7576799270</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>729433</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>910183615240300</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>95955</td>\n",
       "      <td>821548769</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106392</td>\n",
       "      <td>0.12707</td>\n",
       "      <td>0.12707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7576799270-95999-2018-07-09-7500.0</td>\n",
       "      <td>7576799270</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>729433</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>910183615240300</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>95999</td>\n",
       "      <td>821548769</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106392</td>\n",
       "      <td>0.12707</td>\n",
       "      <td>0.12707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7576799270-G0453-2018-07-09-30000.0</td>\n",
       "      <td>7576799270</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>729433</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>910183615240300</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>G0453</td>\n",
       "      <td>821548769</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106392</td>\n",
       "      <td>0.12707</td>\n",
       "      <td>0.12707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   key         icn bil_recv_dt  policy  \\\n",
       "0   7576799270-95870-2018-07-09-7956.0  7576799270  2018-12-27  729433   \n",
       "1   7576799270-95938-2018-07-09-4501.0  7576799270  2018-12-27  729433   \n",
       "2   7576799270-95955-2018-07-09-7500.0  7576799270  2018-12-27  729433   \n",
       "3   7576799270-95999-2018-07-09-7500.0  7576799270  2018-12-27  729433   \n",
       "4  7576799270-G0453-2018-07-09-30000.0  7576799270  2018-12-27  729433   \n",
       "\n",
       "  report_date     ufe_claim_id fst_srvc_dt proc_cd_gal   prov_tin  \\\n",
       "0  2019-04-01  910183615240300  2018-07-09       95870  821548769   \n",
       "1  2019-04-01  910183615240300  2018-07-09       95938  821548769   \n",
       "2  2019-04-01  910183615240300  2018-07-09       95955  821548769   \n",
       "3  2019-04-01  910183615240300  2018-07-09       95999  821548769   \n",
       "4  2019-04-01  910183615240300  2018-07-09       G0453  821548769   \n",
       "\n",
       "   lin_chrg_amt  ... fst_srvc_dt_max bil_diff_fst fst_max_min  \\\n",
       "0        7956.0  ...      2018-07-09        171.0         0.0   \n",
       "1        4501.0  ...      2018-07-09        171.0         0.0   \n",
       "2        7500.0  ...      2018-07-09        171.0         0.0   \n",
       "3        7500.0  ...      2018-07-09        171.0         0.0   \n",
       "4       30000.0  ...      2018-07-09        171.0         0.0   \n",
       "\n",
       "  bil_diff_fst_norm  fst_max_min_norm  bil_diff_fst_norm_log  \\\n",
       "0          0.187375               0.0               0.171745   \n",
       "1          0.187375               0.0               0.171745   \n",
       "2          0.187375               0.0               0.171745   \n",
       "3          0.187375               0.0               0.171745   \n",
       "4          0.187375               0.0               0.171745   \n",
       "\n",
       "  fst_max_min_norm_log  diag_amnt_avg tin_diag_amnt_avg npi_diag_amnt_avg  \n",
       "0                  0.0       0.106392           0.12707           0.12707  \n",
       "1                  0.0       0.106392           0.12707           0.12707  \n",
       "2                  0.0       0.106392           0.12707           0.12707  \n",
       "3                  0.0       0.106392           0.12707           0.12707  \n",
       "4                  0.0       0.106392           0.12707           0.12707  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicators\n",
    "\n",
    "amt_indicator=['diag_amnt_avg','tin_diag_amnt_avg','npi_diag_amnt_avg']\n",
    "for i in amt_indicator:\n",
    "    train[i+'_ind_above']=np.where(train['clm_tot_chrg_amt_v2_norm_log']> train[i],1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicators\n",
    "\n",
    "amt_indicator=['diag_amnt_avg','tin_diag_amnt_avg','npi_diag_amnt_avg']\n",
    "for i in amt_indicator:\n",
    "    test[i+'_ind_above']=np.where(test['clm_tot_chrg_amt_v2_norm_log']> test[i],1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train['uni_agg_norm']=(train['unit_agg']-train['unit_agg'].min())/(train['unit_agg'].max()-train['unit_agg'].min())\n",
    "train['unit_agg_norm_log'] = np.log(train['uni_agg_norm']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test['uni_agg_norm']=(test['unit_agg']-train['unit_agg'].min())/(train['unit_agg'].max()-train['unit_agg'].min())\n",
    "test['unit_agg_norm_log'] = np.log(test['uni_agg_norm']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "['others' 'TX' 'OK' 'NY' 'CA' 'IL' 'WI' 'NJ' 'OH' 'AZ']\n",
      "31\n",
      "['22' '21' 'others' '11' '15']\n"
     ]
    }
   ],
   "source": [
    "train_den = train[train['clm_den_flag'] == 1]\n",
    "\n",
    "\n",
    "## 1.Provider State category\n",
    "\n",
    "train_den_state=train_den.groupby('st_abbr_cd',as_index=False).agg({\"icn\":\"count\"})\n",
    "df_2 = train_den_state.sort_values(by=\"icn\",axis=0,ascending=False)\n",
    "df_2 = df_2.reset_index(drop=True)\n",
    "df_2[\"cum_sum\"] = df_2.icn.cumsum()\n",
    "df_2[\"cum_per\"] = 100*df_2.cum_sum/df_2.icn.sum()\n",
    "df_2[df_2[\"cum_per\"]<=80][\"st_abbr_cd\"]\n",
    "name2= df_2[df_2[\"cum_per\"]<=80][\"st_abbr_cd\"]\n",
    "name2\n",
    "\n",
    "train['st_abbr_cd_bin'] = train.st_abbr_cd.where(train.st_abbr_cd.isin(name2), 'others')\n",
    "print (len(train['st_abbr_cd'].unique()))\n",
    "print (train['st_abbr_cd_bin'].unique())\n",
    "\n",
    "\n",
    "## 2.Place of service\n",
    "\n",
    "train_den_pos=train_den.groupby('plc_of_srvc',as_index=False).agg({\"icn\":\"count\"})\n",
    "df_3 = train_den_pos.sort_values(by=\"icn\",axis=0,ascending=False)\n",
    "df_3 = df_3.reset_index(drop=True)\n",
    "df_3[\"cum_sum\"] = df_3.icn.cumsum()\n",
    "df_3[\"cum_per\"] = 100*df_3.cum_sum/df_3.icn.sum()\n",
    "df_3[df_3[\"cum_per\"]<=80][\"plc_of_srvc\"]\n",
    "name3= df_3[df_3[\"cum_per\"]<=80][\"plc_of_srvc\"]\n",
    "name3\n",
    "\n",
    "train['plc_of_srvc_bin'] = train.plc_of_srvc.where(train.plc_of_srvc.isin(name3), 'others')\n",
    "print (len(train['plc_of_srvc'].unique()))\n",
    "print (train['plc_of_srvc_bin'].unique())\n",
    "\n",
    "\n",
    "### 3.Service billed bin\n",
    "\n",
    "bin1 = [train['bil_diff_fst'].min()-1,90,180,train['bil_diff_fst'].max()+1]\n",
    "train['bil_diff_fst_bin'] = pd.cut(train['bil_diff_fst'], bin1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "['CA' 'NY' 'NJ' 'others' 'AZ' 'TX' 'IL' 'OH' 'WI' 'OK']\n",
      "27\n",
      "['21' 'others' '11' '15' '22']\n"
     ]
    }
   ],
   "source": [
    "#train_den = train[train['clm_den_flag'] == 1]\n",
    "\n",
    "\n",
    "# ## 1.Provider State category\n",
    "\n",
    "# train_den_state=train_den.groupby('st_abbr_cd',as_index=False).agg({\"icn\":\"count\"})\n",
    "# df_2 = train_den_state.sort_values(by=\"icn\",axis=0,ascending=False)\n",
    "# df_2 = df_2.reset_index(drop=True)\n",
    "# df_2[\"cum_sum\"] = df_2.icn.cumsum()\n",
    "# df_2[\"cum_per\"] = 100*df_2.cum_sum/df_2.icn.sum()\n",
    "# df_2[df_2[\"cum_per\"]<=80][\"st_abbr_cd\"]\n",
    "# name2= df_2[df_2[\"cum_per\"]<=80][\"st_abbr_cd\"]\n",
    "# name2\n",
    "\n",
    "test['st_abbr_cd_bin'] = test.st_abbr_cd.where(test.st_abbr_cd.isin(name2), 'others')\n",
    "print (len(test['st_abbr_cd'].unique()))\n",
    "print (test['st_abbr_cd_bin'].unique())\n",
    "\n",
    "\n",
    "## 2.Place of service\n",
    "\n",
    "# train_den_pos=train_den.groupby('plc_of_srvc',as_index=False).agg({\"icn\":\"count\"})\n",
    "# df_3 = train_den_pos.sort_values(by=\"icn\",axis=0,ascending=False)\n",
    "# df_3 = df_3.reset_index(drop=True)\n",
    "# df_3[\"cum_sum\"] = df_3.icn.cumsum()\n",
    "# df_3[\"cum_per\"] = 100*df_3.cum_sum/df_3.icn.sum()\n",
    "# df_3[df_3[\"cum_per\"]<=80][\"plc_of_srvc\"]\n",
    "# name3= df_3[df_3[\"cum_per\"]<=80][\"plc_of_srvc\"]\n",
    "# name3\n",
    "\n",
    "test['plc_of_srvc_bin'] = test.plc_of_srvc.where(test.plc_of_srvc.isin(name3), 'others')\n",
    "print (len(test['plc_of_srvc'].unique()))\n",
    "print (test['plc_of_srvc_bin'].unique())\n",
    "\n",
    "\n",
    "### 3.Service billed bin\n",
    "\n",
    "bin1 = [train['bil_diff_fst'].min()-1,90,180,train['bil_diff_fst'].max()+1]\n",
    "test['bil_diff_fst_bin'] = pd.cut(test['bil_diff_fst'], bin1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 2 binning\n",
    "train_buck = pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(train, pos_bucket_grouped_v2[['plc_of_srvc','pos_denied_prcnt_grp']], on='plc_of_srvc', how='left'), lob_bucket_grouped_v2[['lob','lob_denied_prcnt_grp']], on='lob', how='left'), collect_set_bucket_grouped_v2[['category_set','collect_set_denied_prcnt_grp']], on='category_set', how='left'), cpt_bucket_grouped_v2[['proc_cd_gal','cpt_denied_prcnt_grp']], on='proc_cd_gal', how='left'), tin_bucket_grouped_v2[['prov_tin','tin_denied_prcnt_grp']], on='prov_tin', how='left'), state_bucket_grouped_v2[['st_abbr_cd','state_denied_prcnt_grp']], on='st_abbr_cd', how='left'), diagnosis_bucket_grouped_v2[['diag_3','diag_denied_prcnt_grp']], on='diag_3', how='left'), npi_bucket_grouped_v2[['npi','npi_denied_prcnt_grp']], on='npi', how='left'), policy_bucket_grouped_v2[['policy','policy_denied_prcnt_grp']], on='policy', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 2 binning\n",
    "test_buck = pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(test, pos_bucket_grouped_v2[['plc_of_srvc','pos_denied_prcnt_grp']], on='plc_of_srvc', how='left'), lob_bucket_grouped_v2[['lob','lob_denied_prcnt_grp']], on='lob', how='left'), collect_set_bucket_grouped_v2[['category_set','collect_set_denied_prcnt_grp']], on='category_set', how='left'), cpt_bucket_grouped_v2[['proc_cd_gal','cpt_denied_prcnt_grp']], on='proc_cd_gal', how='left'), tin_bucket_grouped_v2[['prov_tin','tin_denied_prcnt_grp']], on='prov_tin', how='left'), state_bucket_grouped_v2[['st_abbr_cd','state_denied_prcnt_grp']], on='st_abbr_cd', how='left'), diagnosis_bucket_grouped_v2[['diag_3','diag_denied_prcnt_grp']], on='diag_3', how='left'), npi_bucket_grouped_v2[['npi','npi_denied_prcnt_grp']], on='npi', how='left'), policy_bucket_grouped_v2[['policy','policy_denied_prcnt_grp']], on='policy', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_buck = pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(train, pos_bucket_grouped[['plc_of_srvc','pos_denied_prcnt_grp']], on='plc_of_srvc', how='left'), lob_bucket_grouped[['lob','lob_denied_prcnt_grp']], on='lob', how='left'), collect_set_bucket_grouped[['category_set','collect_set_denied_prcnt_grp']], on='category_set', how='left'), cpt_bucket_grouped[['proc_cd_gal','cpt_denied_prcnt_grp']], on='proc_cd_gal', how='left'), tin_bucket_grouped[['prov_tin','tin_denied_prcnt_grp']], on='prov_tin', how='left'), state_bucket_grouped[['st_abbr_cd','state_denied_prcnt_grp']], on='st_abbr_cd', how='left'), diagnosis_bucket_grouped[['diag_3','diag_denied_prcnt_grp']], on='diag_3', how='left'), npi_bucket_grouped[['npi','npi_denied_prcnt_grp']], on='npi', how='left'), policy_bucket_grouped[['policy','policy_denied_prcnt_grp']], on='policy', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G15-45         99909\n",
       "G70-100         9938\n",
       "G0-15           1140\n",
       "G45-70           847\n",
       "Others_Low       363\n",
       "Others_High        3\n",
       "Name: pos_denied_prcnt_grp, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_buck.pos_denied_prcnt_grp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['pos_denied_prcnt_grp', 'lob_denied_prcnt_grp', 'collect_set_denied_prcnt_grp', 'cpt_denied_prcnt_grp',\n",
    "       'tin_denied_prcnt_grp', 'state_denied_prcnt_grp', 'diag_denied_prcnt_grp', 'npi_denied_prcnt_grp',\n",
    "       'policy_denied_prcnt_grp']\n",
    "\n",
    "train_buck[cols]=train_buck[cols].replace({'Others_Low':'Others'})\n",
    "train_buck[cols]=train_buck[cols].replace({'Others_High':'Others'})\n",
    "train_buck[cols]=train_buck[cols].fillna('Others')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['pos_denied_prcnt_grp', 'lob_denied_prcnt_grp', 'collect_set_denied_prcnt_grp', 'cpt_denied_prcnt_grp',\n",
    "       'tin_denied_prcnt_grp', 'state_denied_prcnt_grp', 'diag_denied_prcnt_grp', 'npi_denied_prcnt_grp',\n",
    "       'policy_denied_prcnt_grp']\n",
    "\n",
    "test_buck[cols]=test_buck[cols].replace({'Others_Low':'Others'})\n",
    "test_buck[cols]=test_buck[cols].replace({'Others_High':'Others'})\n",
    "test_buck[cols]=test_buck[cols].fillna('Others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37452\n",
      "(112200, 65)\n"
     ]
    }
   ],
   "source": [
    "print(train_buck['icn'].nunique())\n",
    "print(train_buck.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7918\n",
      "(22853, 65)\n"
     ]
    }
   ],
   "source": [
    "print(test_buck['icn'].nunique())\n",
    "print(test_buck.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['key', 'icn', 'bil_recv_dt', 'policy', 'report_date', 'ufe_claim_id',\n",
       "       'fst_srvc_dt', 'proc_cd_gal', 'prov_tin', 'lin_chrg_amt', 'bth_dt',\n",
       "       'st_abbr_cd', 'diag_cd', 'npi', 'clm_tot_chrg_amt', 'dmg_pat_sex',\n",
       "       'lob', 'units', 'plc_of_srvc', 'proc_sub_cat', 'unlisted_flag',\n",
       "       'srvc_den_flag', 'fk_flag', 'clm_den_flag', 'clm_tot_chrg_amt_v2',\n",
       "       'rw_nm', 'diag_3', 'category_set', 'mem_age', 'listed_presence',\n",
       "       'unit_agg', 'lin_chrg_amt_norm', 'clm_tot_chrg_amt_v2_norm',\n",
       "       'lin_chrg_amt_norm_log', 'clm_tot_chrg_amt_v2_norm_log', 'mem_age_bin',\n",
       "       'bil_recv_month', 'fst_srvc_dt_min', 'fst_srvc_dt_max', 'bil_diff_fst',\n",
       "       'fst_max_min', 'bil_diff_fst_norm', 'fst_max_min_norm',\n",
       "       'bil_diff_fst_norm_log', 'fst_max_min_norm_log', 'diag_amnt_avg',\n",
       "       'tin_diag_amnt_avg', 'npi_diag_amnt_avg', 'diag_amnt_avg_ind_above',\n",
       "       'tin_diag_amnt_avg_ind_above', 'npi_diag_amnt_avg_ind_above',\n",
       "       'uni_agg_norm', 'unit_agg_norm_log', 'st_abbr_cd_bin',\n",
       "       'plc_of_srvc_bin', 'bil_diff_fst_bin', 'pos_denied_prcnt_grp',\n",
       "       'lob_denied_prcnt_grp', 'collect_set_denied_prcnt_grp',\n",
       "       'cpt_denied_prcnt_grp', 'tin_denied_prcnt_grp',\n",
       "       'state_denied_prcnt_grp', 'diag_denied_prcnt_grp',\n",
       "       'npi_denied_prcnt_grp', 'policy_denied_prcnt_grp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_buck.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = train_buck[['icn', 'dmg_pat_sex', 'clm_den_flag', 'listed_presence', 'mem_age_bin', 'unit_agg_norm_log',\n",
    "                          'clm_tot_chrg_amt_v2_norm_log','bil_recv_month', 'pos_denied_prcnt_grp', 'lob_denied_prcnt_grp',\n",
    "                          'collect_set_denied_prcnt_grp', 'cpt_denied_prcnt_grp', 'tin_denied_prcnt_grp', 'state_denied_prcnt_grp',\n",
    "                          'diag_denied_prcnt_grp', 'npi_denied_prcnt_grp','policy_denied_prcnt_grp','bil_diff_fst_norm_log',\n",
    "                          'diag_amnt_avg','tin_diag_amnt_avg', 'npi_diag_amnt_avg', 'diag_amnt_avg_ind_above',\n",
    "                          'tin_diag_amnt_avg_ind_above', 'npi_diag_amnt_avg_ind_above','st_abbr_cd_bin',\n",
    "                          'plc_of_srvc_bin','bil_diff_fst_bin']]\n",
    "\n",
    "\n",
    "train_input.drop_duplicates(inplace=True)\n",
    "train_input['icn'] = train_input['icn'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = test_buck[['icn', 'dmg_pat_sex', 'clm_den_flag', 'listed_presence', 'mem_age_bin', 'unit_agg_norm_log',\n",
    "                          'clm_tot_chrg_amt_v2_norm_log','bil_recv_month', 'pos_denied_prcnt_grp', 'lob_denied_prcnt_grp',\n",
    "                          'collect_set_denied_prcnt_grp', 'cpt_denied_prcnt_grp', 'tin_denied_prcnt_grp', 'state_denied_prcnt_grp',\n",
    "                          'diag_denied_prcnt_grp', 'npi_denied_prcnt_grp','policy_denied_prcnt_grp','bil_diff_fst_norm_log',\n",
    "                          'diag_amnt_avg','tin_diag_amnt_avg', 'npi_diag_amnt_avg', 'diag_amnt_avg_ind_above',\n",
    "                          'tin_diag_amnt_avg_ind_above', 'npi_diag_amnt_avg_ind_above','st_abbr_cd_bin',\n",
    "                          'plc_of_srvc_bin','bil_diff_fst_bin']]\n",
    "\n",
    "\n",
    "test_input.drop_duplicates(inplace=True)\n",
    "test_input['icn'] = test_input['icn'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "icn                                int64\n",
       "dmg_pat_sex                       object\n",
       "clm_den_flag                       int64\n",
       "listed_presence                    int64\n",
       "mem_age_bin                     category\n",
       "unit_agg_norm_log                float64\n",
       "clm_tot_chrg_amt_v2_norm_log     float64\n",
       "bil_recv_month                    object\n",
       "pos_denied_prcnt_grp              object\n",
       "lob_denied_prcnt_grp              object\n",
       "collect_set_denied_prcnt_grp      object\n",
       "cpt_denied_prcnt_grp              object\n",
       "tin_denied_prcnt_grp              object\n",
       "state_denied_prcnt_grp            object\n",
       "diag_denied_prcnt_grp             object\n",
       "npi_denied_prcnt_grp              object\n",
       "policy_denied_prcnt_grp           object\n",
       "bil_diff_fst_norm_log            float64\n",
       "diag_amnt_avg                    float64\n",
       "tin_diag_amnt_avg                float64\n",
       "npi_diag_amnt_avg                float64\n",
       "diag_amnt_avg_ind_above            int64\n",
       "tin_diag_amnt_avg_ind_above        int64\n",
       "npi_diag_amnt_avg_ind_above        int64\n",
       "st_abbr_cd_bin                    object\n",
       "plc_of_srvc_bin                   object\n",
       "bil_diff_fst_bin                category\n",
       "dtype: object"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_input.shape\n",
    "train_input.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_dummy = pd.get_dummies(train_input, drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65562, 105)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13431, 103)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_dummy = pd.get_dummies(test_input, drop_first=False)\n",
    "test_input_dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rollup=train_input_dummy.groupby(['icn', 'clm_den_flag'],as_index=False).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37452, 105)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rollup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7918, 103)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rollup=test_input_dummy.groupby(['icn', 'clm_den_flag'],as_index=False).max()\n",
    "test_rollup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bil_recv_month_9', 'bil_recv_month_6', 'bil_recv_month_7']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=list(train_rollup.columns)\n",
    "b=list(test_rollup.columns)\n",
    "type(a)\n",
    "\n",
    "def Diff(li1, li2): \n",
    "    return (list(set(li1) - set(li2))) \n",
    "Diff(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rollup['bil_recv_month_9']=0\n",
    "test_rollup['bil_recv_month_6']=0\n",
    "test_rollup['bil_recv_month_7']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['collect_set_denied_prcnt_grp_Others']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=list(train_rollup.columns)\n",
    "b=list(test_rollup.columns)\n",
    "type(a)\n",
    "\n",
    "def Diff(li1, li2): \n",
    "    return (list(set(li1) - set(li2))) \n",
    "Diff(b,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rollup=test_rollup.drop(['collect_set_denied_prcnt_grp_Others'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icn</th>\n",
       "      <th>clm_den_flag</th>\n",
       "      <th>listed_presence</th>\n",
       "      <th>unit_agg_norm_log</th>\n",
       "      <th>clm_tot_chrg_amt_v2_norm_log</th>\n",
       "      <th>bil_diff_fst_norm_log</th>\n",
       "      <th>diag_amnt_avg</th>\n",
       "      <th>tin_diag_amnt_avg</th>\n",
       "      <th>npi_diag_amnt_avg</th>\n",
       "      <th>diag_amnt_avg_ind_above</th>\n",
       "      <th>...</th>\n",
       "      <th>st_abbr_cd_bin_WI</th>\n",
       "      <th>st_abbr_cd_bin_others</th>\n",
       "      <th>plc_of_srvc_bin_11</th>\n",
       "      <th>plc_of_srvc_bin_15</th>\n",
       "      <th>plc_of_srvc_bin_21</th>\n",
       "      <th>plc_of_srvc_bin_22</th>\n",
       "      <th>plc_of_srvc_bin_others</th>\n",
       "      <th>bil_diff_fst_bin_(-17.0, 90.0]</th>\n",
       "      <th>bil_diff_fst_bin_(90.0, 180.0]</th>\n",
       "      <th>bil_diff_fst_bin_(180.0, 983.0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3340484014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.009718</td>\n",
       "      <td>0.018859</td>\n",
       "      <td>0.014894</td>\n",
       "      <td>0.009718</td>\n",
       "      <td>0.009718</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3340992779</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.012722</td>\n",
       "      <td>0.021805</td>\n",
       "      <td>0.028265</td>\n",
       "      <td>0.012722</td>\n",
       "      <td>0.012722</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341042986</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.040946</td>\n",
       "      <td>0.095492</td>\n",
       "      <td>0.025261</td>\n",
       "      <td>0.040946</td>\n",
       "      <td>0.040946</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3341073203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008779</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.052695</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3341081536</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.015267</td>\n",
       "      <td>0.017875</td>\n",
       "      <td>0.039434</td>\n",
       "      <td>0.016723</td>\n",
       "      <td>0.016723</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          icn  clm_den_flag  listed_presence  unit_agg_norm_log  \\\n",
       "0  3340484014             0                1           0.001037   \n",
       "1  3340992779             0                1           0.001037   \n",
       "2  3341042986             0                1           0.002590   \n",
       "3  3341073203             0                1           0.008779   \n",
       "4  3341081536             0                1           0.001555   \n",
       "\n",
       "   clm_tot_chrg_amt_v2_norm_log  bil_diff_fst_norm_log  diag_amnt_avg  \\\n",
       "0                      0.009718               0.018859       0.014894   \n",
       "1                      0.012722               0.021805       0.028265   \n",
       "2                      0.040946               0.095492       0.025261   \n",
       "3                      0.005584               0.052695       0.005584   \n",
       "4                      0.015267               0.017875       0.039434   \n",
       "\n",
       "   tin_diag_amnt_avg  npi_diag_amnt_avg  diag_amnt_avg_ind_above  ...  \\\n",
       "0           0.009718           0.009718                        0  ...   \n",
       "1           0.012722           0.012722                        0  ...   \n",
       "2           0.040946           0.040946                        1  ...   \n",
       "3           0.005584           0.005584                        0  ...   \n",
       "4           0.016723           0.016723                        0  ...   \n",
       "\n",
       "   st_abbr_cd_bin_WI  st_abbr_cd_bin_others  plc_of_srvc_bin_11  \\\n",
       "0                  0                      1                   0   \n",
       "1                  0                      1                   0   \n",
       "2                  0                      0                   0   \n",
       "3                  0                      0                   0   \n",
       "4                  0                      1                   0   \n",
       "\n",
       "   plc_of_srvc_bin_15  plc_of_srvc_bin_21  plc_of_srvc_bin_22  \\\n",
       "0                   0                   0                   1   \n",
       "1                   0                   0                   1   \n",
       "2                   0                   1                   0   \n",
       "3                   0                   0                   1   \n",
       "4                   0                   1                   0   \n",
       "\n",
       "   plc_of_srvc_bin_others  bil_diff_fst_bin_(-17.0, 90.0]  \\\n",
       "0                       0                               1   \n",
       "1                       0                               1   \n",
       "2                       0                               1   \n",
       "3                       0                               1   \n",
       "4                       0                               1   \n",
       "\n",
       "   bil_diff_fst_bin_(90.0, 180.0]  bil_diff_fst_bin_(180.0, 983.0]  \n",
       "0                               0                                0  \n",
       "1                               0                                0  \n",
       "2                               0                                0  \n",
       "3                               0                                0  \n",
       "4                               0                                0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rollup.head()\n",
    "#train_rollup.to_csv('/projects/G12/pickle_data/rollup_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of additional created vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.countplot(train_rollup.clm_den_flag)\n",
    "# train_rollup.clm_den_flag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,10))\n",
    "\n",
    "# # NO use\n",
    "# plt.subplot(3,2,1)\n",
    "# sns.boxplot(x=train_rollup.clm_den_flag,y=train_rollup.fst_max_min_norm_log)\n",
    "\n",
    "\n",
    "# plt.subplot(3,2,2)\n",
    "# sns.boxplot(x=train_rollup.clm_den_flag,y=train_rollup.bil_diff_fst_norm_log)\n",
    "\n",
    "# plt.subplot(3,2,3)\n",
    "# sns.boxplot(x=train_rollup.clm_den_flag,y=train_rollup.diag_amnt_avg)\n",
    "\n",
    "# plt.subplot(3,2,4)\n",
    "# sns.boxplot(x=train_rollup.clm_den_flag,y=train_rollup.tin_diag_amnt_avg)\n",
    "\n",
    "# plt.subplot(3,2,5)\n",
    "# sns.boxplot(x=train_rollup.clm_den_flag,y=train_rollup.npi_diag_amnt_avg)\n",
    "\n",
    "\n",
    "# plt.subplot(3,2,6)\n",
    "# sns.boxplot(x=train_rollup.clm_den_flag,y=train_rollup.bil_diff_fst_norm_log)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(25, 6))\n",
    "\n",
    "# df = pd.DataFrame(train_rollup.groupby(['npi_diag_amnt_avg_ind_above'])['clm_den_flag'].count())\n",
    "# df.plot.bar()\n",
    "# plt.title('npi avg amnt vs clm')\n",
    "# plt.show()\n",
    "\n",
    "# train_rollup_den=train_rollup[train_rollup['clm_den_flag']==1]\n",
    "\n",
    "# df1 = pd.DataFrame(train_rollup_den.groupby(['npi_diag_amnt_avg_ind_above'])['clm_den_flag'].count())\n",
    "# df1.plot.bar()\n",
    "# plt.title('npi avg amnt vs den clm')\n",
    "# plt.show()\n",
    "\n",
    "# print(df)\n",
    "# print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train_rollup.drop(['icn', 'clm_den_flag'],axis=1)\n",
    "X.shape\n",
    "y=train_rollup['clm_den_flag'].values\n",
    "y.shape\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20,random_state=3,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=9, max_features='auto',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=800, n_jobs=None, oob_score=True,\n",
       "                       random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rf= RandomForestClassifier(class_weight='balanced',random_state=42)\n",
    "# rf.fit(X_train,y_train)\n",
    "\n",
    "rf= RandomForestClassifier(random_state=42,oob_score=True,n_estimators=800,max_depth=9,class_weight='balanced',\n",
    "                          )\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29961, 105)\n",
      "(29961,)\n",
      "(29961,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89     21489\n",
      "           1       0.74      0.72      0.73      8472\n",
      "\n",
      "    accuracy                           0.85     29961\n",
      "   macro avg       0.81      0.81      0.81     29961\n",
      "weighted avg       0.85      0.85      0.85     29961\n",
      "\n",
      "[[19344  2145]\n",
      " [ 2400  6072]]\n",
      "(7491,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89      5373\n",
      "           1       0.72      0.70      0.71      2118\n",
      "\n",
      "    accuracy                           0.84      7491\n",
      "   macro avg       0.80      0.79      0.80      7491\n",
      "weighted avg       0.84      0.84      0.84      7491\n",
      "\n",
      "[[4804  569]\n",
      " [ 645 1473]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "y_pred = rf.predict(X_train)\n",
    "\n",
    "\n",
    "# Evaluation train\n",
    "print(y_pred.shape)\n",
    "print(classification_report(y_train,y_pred))\n",
    "print(confusion_matrix(y_train,y_pred))\n",
    "\n",
    "# Evaluation validate\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(y_pred.shape)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(rf, X, y, cv=5,scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57507082, 0.69169027, 0.65203022, 0.7115203 , 0.72521246])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>importance</th>\n",
       "      <th>cum_sum</th>\n",
       "      <th>cum_per</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tin_denied_prcnt_grp_G60-100</td>\n",
       "      <td>0.093464</td>\n",
       "      <td>0.093464</td>\n",
       "      <td>9.346358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>policy_denied_prcnt_grp_Others_High</td>\n",
       "      <td>0.080770</td>\n",
       "      <td>0.174234</td>\n",
       "      <td>17.423359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cpt_denied_prcnt_grp_G60-100</td>\n",
       "      <td>0.070594</td>\n",
       "      <td>0.244827</td>\n",
       "      <td>24.482712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>npi_denied_prcnt_grp_G40-70</td>\n",
       "      <td>0.057427</td>\n",
       "      <td>0.302254</td>\n",
       "      <td>30.225375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>npi_denied_prcnt_grp_G0-15</td>\n",
       "      <td>0.053539</td>\n",
       "      <td>0.355793</td>\n",
       "      <td>35.579318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>unit_agg_norm_log</td>\n",
       "      <td>0.040878</td>\n",
       "      <td>0.396671</td>\n",
       "      <td>39.667114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>diag_amnt_avg</td>\n",
       "      <td>0.032420</td>\n",
       "      <td>0.429091</td>\n",
       "      <td>42.909084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>collect_set_denied_prcnt_grp_G0-20</td>\n",
       "      <td>0.030004</td>\n",
       "      <td>0.459095</td>\n",
       "      <td>45.909515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>diag_denied_prcnt_grp_G0-15</td>\n",
       "      <td>0.029131</td>\n",
       "      <td>0.488227</td>\n",
       "      <td>48.822662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>npi_denied_prcnt_grp_Others_High</td>\n",
       "      <td>0.028933</td>\n",
       "      <td>0.517160</td>\n",
       "      <td>51.715987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tin_denied_prcnt_grp_G30-60</td>\n",
       "      <td>0.024897</td>\n",
       "      <td>0.542057</td>\n",
       "      <td>54.205724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tin_diag_amnt_avg</td>\n",
       "      <td>0.023687</td>\n",
       "      <td>0.565744</td>\n",
       "      <td>56.574425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>collect_set_denied_prcnt_grp_G50-100</td>\n",
       "      <td>0.023645</td>\n",
       "      <td>0.589389</td>\n",
       "      <td>58.938916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tin_denied_prcnt_grp_Others_High</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.612947</td>\n",
       "      <td>61.294703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>npi_diag_amnt_avg</td>\n",
       "      <td>0.021793</td>\n",
       "      <td>0.634740</td>\n",
       "      <td>63.473999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tin_denied_prcnt_grp_G05-20</td>\n",
       "      <td>0.019842</td>\n",
       "      <td>0.654582</td>\n",
       "      <td>65.458177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>npi_denied_prcnt_grp_Others_Low</td>\n",
       "      <td>0.019770</td>\n",
       "      <td>0.674351</td>\n",
       "      <td>67.435133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>clm_tot_chrg_amt_v2_norm_log</td>\n",
       "      <td>0.019374</td>\n",
       "      <td>0.693725</td>\n",
       "      <td>69.372504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bil_diff_fst_norm_log</td>\n",
       "      <td>0.018652</td>\n",
       "      <td>0.712377</td>\n",
       "      <td>71.237666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>policy_denied_prcnt_grp_Others_Low</td>\n",
       "      <td>0.018535</td>\n",
       "      <td>0.730911</td>\n",
       "      <td>73.091119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cpt_denied_prcnt_grp_G40-60</td>\n",
       "      <td>0.017624</td>\n",
       "      <td>0.748536</td>\n",
       "      <td>74.853552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>npi_denied_prcnt_grp_G0</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>0.764386</td>\n",
       "      <td>76.438577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>npi_denied_prcnt_grp_G90-100</td>\n",
       "      <td>0.014598</td>\n",
       "      <td>0.778984</td>\n",
       "      <td>77.898391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cpt_denied_prcnt_grp_G20-40</td>\n",
       "      <td>0.013476</td>\n",
       "      <td>0.792460</td>\n",
       "      <td>79.246037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>diag_denied_prcnt_grp_G55-75</td>\n",
       "      <td>0.012889</td>\n",
       "      <td>0.805349</td>\n",
       "      <td>80.534944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cpt_denied_prcnt_grp_G05-10</td>\n",
       "      <td>0.012528</td>\n",
       "      <td>0.817877</td>\n",
       "      <td>81.787741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tin_denied_prcnt_grp_Others_Low</td>\n",
       "      <td>0.012217</td>\n",
       "      <td>0.830094</td>\n",
       "      <td>83.009430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>diag_denied_prcnt_grp_G75-100</td>\n",
       "      <td>0.011566</td>\n",
       "      <td>0.841660</td>\n",
       "      <td>84.165993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>npi_denied_prcnt_grp_G15-40</td>\n",
       "      <td>0.011504</td>\n",
       "      <td>0.853164</td>\n",
       "      <td>85.316399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>npi_denied_prcnt_grp_G70-90</td>\n",
       "      <td>0.009670</td>\n",
       "      <td>0.862834</td>\n",
       "      <td>86.283405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>mem_age_bin_(45.0, 60.0]</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.988031</td>\n",
       "      <td>98.803139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>diag_amnt_avg_ind_above</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.988881</td>\n",
       "      <td>98.888118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>state_denied_prcnt_grp_G15-25</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.989570</td>\n",
       "      <td>98.956983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>mem_age_bin_(60.0, 146.0]</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.990257</td>\n",
       "      <td>99.025662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>bil_recv_month_1</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.990936</td>\n",
       "      <td>99.093553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>bil_recv_month_10</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.991581</td>\n",
       "      <td>99.158124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>policy_denied_prcnt_grp_G50-100</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.992220</td>\n",
       "      <td>99.221970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>bil_recv_month_11</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.992858</td>\n",
       "      <td>99.285803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>bil_recv_month_4</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.993463</td>\n",
       "      <td>99.346297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>collect_set_denied_prcnt_grp_G30-50</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.994042</td>\n",
       "      <td>99.404178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>bil_recv_month_7</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.994616</td>\n",
       "      <td>99.461627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>mem_age_bin_(0.0, 20.0]</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.995175</td>\n",
       "      <td>99.517454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>bil_recv_month_8</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.995729</td>\n",
       "      <td>99.572901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>bil_recv_month_12</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.996264</td>\n",
       "      <td>99.626437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>bil_recv_month_9</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.996800</td>\n",
       "      <td>99.679973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>st_abbr_cd_bin_IL</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.997250</td>\n",
       "      <td>99.725026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>state_denied_prcnt_grp_G50-100</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.997642</td>\n",
       "      <td>99.764214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>st_abbr_cd_bin_WI</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>99.799989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>st_abbr_cd_bin_NJ</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.998285</td>\n",
       "      <td>99.828534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>lob_denied_prcnt_grp_G50-100</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.998568</td>\n",
       "      <td>99.856789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>st_abbr_cd_bin_OH</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.998828</td>\n",
       "      <td>99.882792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>pos_denied_prcnt_grp_G45-70</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.999083</td>\n",
       "      <td>99.908330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>pos_denied_prcnt_grp_G0-15</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.999306</td>\n",
       "      <td>99.930584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>st_abbr_cd_bin_OK</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.999510</td>\n",
       "      <td>99.950984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>diag_denied_prcnt_grp_Others_High</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.999694</td>\n",
       "      <td>99.969396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>pos_denied_prcnt_grp_Others_Low</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.999869</td>\n",
       "      <td>99.986915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>policy_denied_prcnt_grp_G0</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>99.994209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>state_denied_prcnt_grp_Others_Low</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>99.999052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>pos_denied_prcnt_grp_Others_High</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>state_denied_prcnt_grp_Others_High</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Variable  importance   cum_sum     cum_per\n",
       "0            tin_denied_prcnt_grp_G60-100    0.093464  0.093464    9.346358\n",
       "1     policy_denied_prcnt_grp_Others_High    0.080770  0.174234   17.423359\n",
       "2            cpt_denied_prcnt_grp_G60-100    0.070594  0.244827   24.482712\n",
       "3             npi_denied_prcnt_grp_G40-70    0.057427  0.302254   30.225375\n",
       "4              npi_denied_prcnt_grp_G0-15    0.053539  0.355793   35.579318\n",
       "5                       unit_agg_norm_log    0.040878  0.396671   39.667114\n",
       "6                           diag_amnt_avg    0.032420  0.429091   42.909084\n",
       "7      collect_set_denied_prcnt_grp_G0-20    0.030004  0.459095   45.909515\n",
       "8             diag_denied_prcnt_grp_G0-15    0.029131  0.488227   48.822662\n",
       "9        npi_denied_prcnt_grp_Others_High    0.028933  0.517160   51.715987\n",
       "10            tin_denied_prcnt_grp_G30-60    0.024897  0.542057   54.205724\n",
       "11                      tin_diag_amnt_avg    0.023687  0.565744   56.574425\n",
       "12   collect_set_denied_prcnt_grp_G50-100    0.023645  0.589389   58.938916\n",
       "13       tin_denied_prcnt_grp_Others_High    0.023558  0.612947   61.294703\n",
       "14                      npi_diag_amnt_avg    0.021793  0.634740   63.473999\n",
       "15            tin_denied_prcnt_grp_G05-20    0.019842  0.654582   65.458177\n",
       "16        npi_denied_prcnt_grp_Others_Low    0.019770  0.674351   67.435133\n",
       "17           clm_tot_chrg_amt_v2_norm_log    0.019374  0.693725   69.372504\n",
       "18                  bil_diff_fst_norm_log    0.018652  0.712377   71.237666\n",
       "19     policy_denied_prcnt_grp_Others_Low    0.018535  0.730911   73.091119\n",
       "20            cpt_denied_prcnt_grp_G40-60    0.017624  0.748536   74.853552\n",
       "21                npi_denied_prcnt_grp_G0    0.015850  0.764386   76.438577\n",
       "22           npi_denied_prcnt_grp_G90-100    0.014598  0.778984   77.898391\n",
       "23            cpt_denied_prcnt_grp_G20-40    0.013476  0.792460   79.246037\n",
       "24           diag_denied_prcnt_grp_G55-75    0.012889  0.805349   80.534944\n",
       "25            cpt_denied_prcnt_grp_G05-10    0.012528  0.817877   81.787741\n",
       "26        tin_denied_prcnt_grp_Others_Low    0.012217  0.830094   83.009430\n",
       "27          diag_denied_prcnt_grp_G75-100    0.011566  0.841660   84.165993\n",
       "28            npi_denied_prcnt_grp_G15-40    0.011504  0.853164   85.316399\n",
       "29            npi_denied_prcnt_grp_G70-90    0.009670  0.862834   86.283405\n",
       "..                                    ...         ...       ...         ...\n",
       "75               mem_age_bin_(45.0, 60.0]    0.000861  0.988031   98.803139\n",
       "76                diag_amnt_avg_ind_above    0.000850  0.988881   98.888118\n",
       "77          state_denied_prcnt_grp_G15-25    0.000689  0.989570   98.956983\n",
       "78              mem_age_bin_(60.0, 146.0]    0.000687  0.990257   99.025662\n",
       "79                       bil_recv_month_1    0.000679  0.990936   99.093553\n",
       "80                      bil_recv_month_10    0.000646  0.991581   99.158124\n",
       "81        policy_denied_prcnt_grp_G50-100    0.000638  0.992220   99.221970\n",
       "82                      bil_recv_month_11    0.000638  0.992858   99.285803\n",
       "83                       bil_recv_month_4    0.000605  0.993463   99.346297\n",
       "84    collect_set_denied_prcnt_grp_G30-50    0.000579  0.994042   99.404178\n",
       "85                       bil_recv_month_7    0.000574  0.994616   99.461627\n",
       "86                mem_age_bin_(0.0, 20.0]    0.000558  0.995175   99.517454\n",
       "87                       bil_recv_month_8    0.000554  0.995729   99.572901\n",
       "88                      bil_recv_month_12    0.000535  0.996264   99.626437\n",
       "89                       bil_recv_month_9    0.000535  0.996800   99.679973\n",
       "90                      st_abbr_cd_bin_IL    0.000451  0.997250   99.725026\n",
       "91         state_denied_prcnt_grp_G50-100    0.000392  0.997642   99.764214\n",
       "92                      st_abbr_cd_bin_WI    0.000358  0.998000   99.799989\n",
       "93                      st_abbr_cd_bin_NJ    0.000285  0.998285   99.828534\n",
       "94           lob_denied_prcnt_grp_G50-100    0.000283  0.998568   99.856789\n",
       "95                      st_abbr_cd_bin_OH    0.000260  0.998828   99.882792\n",
       "96            pos_denied_prcnt_grp_G45-70    0.000255  0.999083   99.908330\n",
       "97             pos_denied_prcnt_grp_G0-15    0.000223  0.999306   99.930584\n",
       "98                      st_abbr_cd_bin_OK    0.000204  0.999510   99.950984\n",
       "99      diag_denied_prcnt_grp_Others_High    0.000184  0.999694   99.969396\n",
       "100       pos_denied_prcnt_grp_Others_Low    0.000175  0.999869   99.986915\n",
       "101            policy_denied_prcnt_grp_G0    0.000073  0.999942   99.994209\n",
       "102     state_denied_prcnt_grp_Others_Low    0.000048  0.999991   99.999052\n",
       "103      pos_denied_prcnt_grp_Others_High    0.000009  1.000000  100.000000\n",
       "104    state_denied_prcnt_grp_Others_High    0.000000  1.000000  100.000000\n",
       "\n",
       "[105 rows x 4 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp=rf.feature_importances_\n",
    "names=X.columns.values\n",
    "imp,names=zip(*sorted(zip(imp,names)))\n",
    "\n",
    "df_1=pd.DataFrame({\"Variable\":names,\"importance\":imp})\n",
    "df_2 = df_1.sort_values(by=\"importance\",axis=0,ascending=False)\n",
    "df_2 = df_2.reset_index(drop=True)\n",
    "df_2[\"cum_sum\"] = df_2.importance.cumsum()\n",
    "df_2[\"cum_per\"] = 100*df_2.cum_sum/df_2.importance.sum()\n",
    "df_2\n",
    "#df_2.to_csv('/projects/G12/pickle_data/dummy_imp_dev.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False  True False  True  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False  True  True  True  True\n",
      " False  True  True False False  True  True  True False False False False\n",
      " False  True False False  True False False False False False  True False\n",
      "  True  True False  True  True  True  True  True  True  True  True  True\n",
      " False  True  True False False False False False False  True False False\n",
      " False False False False False False False False False]\n",
      "[56 43 64 15  1 40  1  1 59 46 47 29 27 26 28 67 44 32 49 17  8 48 68 69\n",
      " 66 74 62 11 10 75 12 72 61 55  1 33  9 58 42 19 57 35 65 16  1  1  1  1\n",
      " 18  1  1 53 20  1  1  1 63 54 36 38  7  1 76 60  1 31 39 71 34  3  1 30\n",
      "  1  1 14  1  1  1  1  1  1  1  1  1 52  1  1  6 51 73 41 37  4  1  5 70\n",
      " 50 25 21 23 24 22 45  2 13]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['bil_diff_fst_norm_log', 'tin_diag_amnt_avg', 'npi_diag_amnt_avg',\n",
       "       'lob_denied_prcnt_grp_G20-30', 'cpt_denied_prcnt_grp_G20-40',\n",
       "       'cpt_denied_prcnt_grp_G40-60', 'cpt_denied_prcnt_grp_G60-100',\n",
       "       'cpt_denied_prcnt_grp_Others_High', 'tin_denied_prcnt_grp_G0',\n",
       "       'tin_denied_prcnt_grp_G0-05', 'tin_denied_prcnt_grp_G30-60',\n",
       "       'tin_denied_prcnt_grp_G60-100', 'tin_denied_prcnt_grp_Others_High',\n",
       "       'state_denied_prcnt_grp_G50-100', 'diag_denied_prcnt_grp_G0-15',\n",
       "       'diag_denied_prcnt_grp_Others_High', 'npi_denied_prcnt_grp_G0',\n",
       "       'npi_denied_prcnt_grp_G0-15', 'npi_denied_prcnt_grp_G40-70',\n",
       "       'npi_denied_prcnt_grp_G70-90', 'npi_denied_prcnt_grp_G90-100',\n",
       "       'npi_denied_prcnt_grp_Others_High', 'npi_denied_prcnt_grp_Others_Low',\n",
       "       'policy_denied_prcnt_grp_G0', 'policy_denied_prcnt_grp_G0-20',\n",
       "       'policy_denied_prcnt_grp_G20-30', 'policy_denied_prcnt_grp_G30-50',\n",
       "       'policy_denied_prcnt_grp_Others_High',\n",
       "       'policy_denied_prcnt_grp_Others_Low', 'st_abbr_cd_bin_OK'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(class_weight='balanced',random_state=42)\n",
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(logreg, 30)       \n",
    "rfe = rfe.fit(X_train,y_train)\n",
    "print(rfe.support_)           # Printing the boolean results\n",
    "print(rfe.ranking_)           # Printing the ranking\n",
    "col = X_train.columns[rfe.support_]\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_imp=pd.read_csv(\"/mapr/projects/MCR_Threshold/Data/dummy_imp_dev.csv\")\n",
    "name = df_2[df_2[\"cum_per\"]<=20][\"Variable\"]\n",
    "\n",
    "name=np.append(name, ['clm_den_flag','icn'])\n",
    "name=np.append(col, ['clm_den_flag','icn'])\n",
    "\n",
    "df_d=train_rollup[name]\n",
    "X=df_d.drop(['icn', 'clm_den_flag'],axis=1)\n",
    "X.shape\n",
    "y=df_d['clm_den_flag'].values\n",
    "y.shape\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25,random_state=3,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=9, max_features='auto',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=800, n_jobs=None, oob_score=True,\n",
       "                       random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf= RandomForestClassifier(random_state=42,oob_score=True,n_estimators=800,max_depth=9,class_weight='balanced')\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28089,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89     20146\n",
      "           1       0.74      0.68      0.71      7943\n",
      "\n",
      "    accuracy                           0.84     28089\n",
      "   macro avg       0.81      0.79      0.80     28089\n",
      "weighted avg       0.84      0.84      0.84     28089\n",
      "\n",
      "[[18231  1915]\n",
      " [ 2529  5414]]\n",
      "Score:  0.8417886005197764\n",
      "(9363,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89      6716\n",
      "           1       0.73      0.67      0.70      2647\n",
      "\n",
      "    accuracy                           0.84      9363\n",
      "   macro avg       0.80      0.79      0.79      9363\n",
      "weighted avg       0.83      0.84      0.83      9363\n",
      "\n",
      "[[6048  668]\n",
      " [ 872 1775]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = rf.predict(X_train)\n",
    "\n",
    "\n",
    "# Evaluation train\n",
    "print(y_pred.shape)\n",
    "print(classification_report(y_train,y_pred))\n",
    "print(confusion_matrix(y_train,y_pred))\n",
    "print('Score: ', rf.score(X_train, y_train))\n",
    "\n",
    "# Evaluation validate\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(y_pred.shape)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62983947, 0.71057602, 0.66572238, 0.66241737, 0.69499528])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(rf, X, y, cv=5,scoring='recall')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mean_train_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-76af23ff558f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m plt.plot(scores[\"param_max_depth\"], \n\u001b[0;32m---> 29\u001b[0;31m          \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean_train_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m          label=\"training recall\")\n\u001b[1;32m     31\u001b[0m plt.plot(scores[\"param_max_depth\"], \n",
      "\u001b[0;31mKeyError\u001b[0m: 'mean_train_score'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########## lets tune hyper parameterss   \n",
    "# GridSearchCV to find optimal max_depth   \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_depth': range(1, 40)}\n",
    "\n",
    "# instantiate the model\n",
    "dtree = RandomForestClassifier(class_weight='balanced', random_state = 42)\n",
    "\n",
    "# fit tree on training data\n",
    "tree = GridSearchCV(dtree, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"recall\")\n",
    "tree.fit(X_train,y_train)\n",
    "\n",
    "# scores of GridSearch CV\n",
    "scores = tree.cv_results_\n",
    "pd.DataFrame(scores).head()\n",
    "\n",
    "# plotting accuracies with max_depth\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training recall\")\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test recall\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"recall\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV  100 150\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'n_estimators':  [5,100,200,300,400,500,600,800,1000]}\n",
    "\n",
    "# instantiate the model\n",
    "dtree = RandomForestClassifier(class_weight='balanced', random_state = 42)\n",
    "\n",
    "# fit tree on training data\n",
    "tree = GridSearchCV(dtree, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"recall\")\n",
    "tree.fit(X_train,y_train)\n",
    "\n",
    "# scores of GridSearch CV\n",
    "scores = tree.cv_results_\n",
    "pd.DataFrame(scores).head()\n",
    "\n",
    "# plotting accuracies with max_depth\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_n_estimators\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training recall\")\n",
    "plt.plot(scores[\"param_n_estimators\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test recall\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"recall\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_split' : range(50, 1000, 100)}\n",
    "\n",
    "# instantiate the model\n",
    "dtree = RandomForestClassifier(class_weight='balanced', random_state = 42)\n",
    "\n",
    "# fit tree on training data\n",
    "tree = GridSearchCV(dtree, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"recall\")\n",
    "tree.fit(X_train,y_train)\n",
    "\n",
    "# scores of GridSearch CV\n",
    "scores = tree.cv_results_\n",
    "pd.DataFrame(scores).head()\n",
    "\n",
    "# plotting accuracies with max_depth\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training recall\")\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test recall\")\n",
    "plt.xlabel(\"min_samples_split\")\n",
    "plt.ylabel(\"recall\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_leaf': range(5, 500, 20)}\n",
    "\n",
    "# instantiate the model\n",
    "dtree = RandomForestClassifier(class_weight='balanced', random_state = 42)\n",
    "\n",
    "# fit tree on training data\n",
    "tree = GridSearchCV(dtree, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"recall\")\n",
    "tree.fit(X_train,y_train)\n",
    "\n",
    "# scores of GridSearch CV\n",
    "scores = tree.cv_results_\n",
    "pd.DataFrame(scores).head()\n",
    "\n",
    "# plotting accuracies with max_depth\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training recall\")\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test recall\")\n",
    "plt.xlabel(\"min_samples_leaf\")\n",
    "plt.ylabel(\"recall\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  72 | elapsed:   22.7s remaining:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  72 | elapsed:   23.9s remaining:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:   32.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'class_weight': 'balanced',\n",
       " 'max_depth': 11,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 90,\n",
       " 'min_samples_split': 210,\n",
       " 'n_estimators': 800,\n",
       " 'random_state': 42}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [10,11],\n",
    "    'max_features': ['sqrt','auto'],\n",
    "    'min_samples_leaf': range(50, 120, 40),\n",
    "    'min_samples_split':  range(150, 220, 30),\n",
    "    'n_estimators': [800],\n",
    "    'class_weight':['balanced'],\n",
    "    'random_state':[42]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2,scoring='recall')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=11, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=90,\n",
       "                       min_samples_split=210, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=1500, n_jobs=None, oob_score=False,\n",
       "                       random_state=9, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf= RandomForestClassifier(max_depth=11, class_weight='balanced', n_estimators=1500, max_features = 'sqrt', min_samples_split =210, random_state=9, min_samples_leaf = 90)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28089,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88     20146\n",
      "           1       0.69      0.70      0.69      7943\n",
      "\n",
      "    accuracy                           0.83     28089\n",
      "   macro avg       0.78      0.79      0.79     28089\n",
      "weighted avg       0.83      0.83      0.83     28089\n",
      "\n",
      "[[17664  2482]\n",
      " [ 2418  5525]]\n",
      "Score:  0.8255544875218057\n",
      "(9363,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      6716\n",
      "           1       0.69      0.69      0.69      2647\n",
      "\n",
      "    accuracy                           0.82      9363\n",
      "   macro avg       0.78      0.78      0.78      9363\n",
      "weighted avg       0.82      0.82      0.82      9363\n",
      "\n",
      "[[5885  831]\n",
      " [ 821 1826]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = rf.predict(X_train)\n",
    "\n",
    "\n",
    "# Evaluation train\n",
    "print(y_pred.shape)\n",
    "print(classification_report(y_train,y_pred))\n",
    "print(confusion_matrix(y_train,y_pred))\n",
    "print('Score: ', rf.score(X_train, y_train))\n",
    "\n",
    "# Evaluation validate\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(y_pred.shape)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64447592, 0.73040604, 0.69782814, 0.67988669, 0.70774315])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(rf, X, y, cv=5,scoring='recall')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "##out of sample\n",
    "inscope_inclu_oos = pd.read_pickle('/projects/G12/pickle_data/inscope_inclu_oos.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "oos = inscope_inclu_oos.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obj = oos.select_dtypes(['object'])\n",
    "oos[df_obj.columns] = df_obj.apply(lambda x: x.str.strip().str.upper()).replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cat = oos.select_dtypes(['object']).columns\n",
    "cols_cont = oos.select_dtypes(['float','int']).columns\n",
    "\n",
    "## from above\n",
    "\n",
    "mode_fill = train[cols_cat].mode().iloc[0]\n",
    "median_fill = train[cols_cont].median()\n",
    "\n",
    "oos[cols_cat]=oos[cols_cat].fillna(mode_fill)\n",
    "oos[cols_cont]=oos[cols_cont].fillna(median_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_min_lin = train['lin_chrg_amt'].min()\n",
    "train_max_lin = train['lin_chrg_amt'].max()\n",
    "\n",
    "train_min_clm = train['clm_tot_chrg_amt_v2'].min()\n",
    "train_max_clm = train['clm_tot_chrg_amt_v2'].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "oos['lin_chrg_amt_norm']=(oos['lin_chrg_amt']-train_min_lin)/(train_max_lin-train_min_lin)\n",
    "oos['clm_tot_chrg_amt_v2_norm']=(oos['clm_tot_chrg_amt_v2']-train_min_clm)/(train_max_clm-train_min_clm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "oos['lin_chrg_amt_norm_log'] = np.log(oos['lin_chrg_amt_norm']+1)\n",
    "oos['clm_tot_chrg_amt_v2_norm_log'] = np.log(oos['clm_tot_chrg_amt_v2_norm']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin1 = [train['mem_age'].min()-1,20,45,60,train['mem_age'].max()+1]\n",
    "oos['mem_age_bin'] = pd.cut(oos['mem_age'], bin1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "oos['dmg_pat_sex']=np.where(oos['dmg_pat_sex']=='F',0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "oos['bil_recv_dt']=pd.to_datetime(oos['bil_recv_dt'], format = \"%Y-%m-%d\")\n",
    "oos['bil_recv_month'] = oos['bil_recv_dt'].apply(lambda x: x.month)\n",
    "oos['bil_recv_month'] = oos['bil_recv_month'].astype(str)\n",
    "# month_bucket_grouped['bil_recv_month'] = month_bucket_grouped['bil_recv_month'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=None, oob_score=True, random_state=9,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf= RandomForestClassifier(class_weight='balanced',random_state=9, oob_score= True)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26216, 80)\n",
      "(26216,)\n",
      "(26216,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97     18818\n",
      "           1       0.93      0.93      0.93      7398\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     26216\n",
      "   macro avg       0.95      0.95      0.95     26216\n",
      "weighted avg       0.96      0.96      0.96     26216\n",
      "\n",
      "[[18302   516]\n",
      " [  489  6909]]\n",
      "Score:  0.9616646322856272\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "y_pred = rf.predict(X_train)\n",
    "\n",
    "\n",
    "# Evaluation train\n",
    "print(y_pred.shape)\n",
    "print(classification_report(y_train,y_pred))\n",
    "print(confusion_matrix(y_train,y_pred))\n",
    "print('Score: ', rf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11236,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      8044\n",
      "           1       0.76      0.62      0.68      3192\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     11236\n",
      "   macro avg       0.81      0.77      0.79     11236\n",
      "weighted avg       0.83      0.84      0.83     11236\n",
      "\n",
      "[[7404  640]\n",
      " [1210 1982]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluation validate\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(y_pred.shape)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp=rf.feature_importances_\n",
    "names=X.columns.values\n",
    "imp,names=zip(*sorted(zip(imp,names)))\n",
    "\n",
    "df_1=pd.DataFrame({\"Variable\":names,\"importance\":imp})\n",
    "df_2 = df_1.sort_values(by=\"importance\",axis=0,ascending=False)\n",
    "df_2 = df_2.reset_index(drop=True)\n",
    "df_2[\"cum_sum\"] = df_2.importance.cumsum()\n",
    "df_2[\"cum_per\"] = 100*df_2.cum_sum/df_2.importance.sum()\n",
    "# df_2\n",
    "#df_2.to_csv('/mapr/projects/MCR_Threshold/Data/dummy_imp_dev.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAAELCAYAAADnZCEkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GridSearchCV to find optimal n_estimators\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_depth': range(4, 24, 2)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"recall\", n_jobs=-1,return_train_score=True)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "df = pd.DataFrame(scores)\n",
    "\n",
    "# plotting accuracies with max_depth\n",
    "plt.figure()\n",
    "plt.plot(df[\"param_max_depth\"], \n",
    "         df[\"mean_train_score\"])\n",
    "plt.plot(df[\"param_max_depth\"], \n",
    "         df[\"mean_test_score\"])\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAAELCAYAAADnZCEkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GridSearchCV to find optimal n_estimators\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'n_estimators': range(500, 2000, 400)}\n",
    "\n",
    "# instantiate the model (note we are specifying a max_depth)\n",
    "rf = RandomForestClassifier(max_depth=12, class_weight='balanced')\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"recall\", n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "df = pd.DataFrame(scores)\n",
    "\n",
    "# plotting accuracies with n_estimators\n",
    "plt.figure()\n",
    "plt.plot(df[\"param_n_estimators\"], \n",
    "         df[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(df[\"param_n_estimators\"], \n",
    "         df[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-dad16864315d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                    scoring=\"recall\")\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# scores of GridSearch CV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 333\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# GridSearchCV to find optimal max_features\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_features': [4,6,8,10,12]}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier(max_depth=12, class_weight='balanced',n_estimators=900)\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"recall\")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "df = pd.DataFrame(scores)\n",
    "\n",
    "# plotting accuracies with n_estimators\n",
    "plt.figure()\n",
    "plt.plot(df[\"param_max_features\"], df[\"mean_train_score\"], label=\"training accuracy\")\n",
    "plt.plot(df[\"param_max_features\"], df[\"mean_test_score\"],  label=\"test accuracy\")\n",
    "plt.xlabel(\"max_features\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max _feature 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuEAAAELCAYAAAB3d1jrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIfaGigAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # GridSearchCV to find optimal max_features\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# # specify number of folds for k-fold CV\n",
    "# n_folds = 5\n",
    "\n",
    "# # parameters to build the model on\n",
    "# parameters = {'min_samples_split': range(4, 14, 2)}\n",
    "\n",
    "# # instantiate the model\n",
    "# rf = RandomForestClassifier(max_depth=12, class_weight='balanced',n_estimators=900, max_features = 6)\n",
    "\n",
    "\n",
    "# # fit tree on training data\n",
    "# rf = GridSearchCV(rf, parameters, \n",
    "#                     cv=n_folds, \n",
    "#                    scoring=\"recall\")\n",
    "# rf.fit(X_train, y_train)\n",
    "\n",
    "# # scores of GridSearch CV\n",
    "# scores = rf.cv_results_\n",
    "# df = pd.DataFrame(scores)\n",
    "\n",
    "# # plotting accuracies with n_estimators\n",
    "# plt.figure()\n",
    "# plt.plot(df[\"param_min_samples_split\"], \n",
    "#          df[\"mean_train_score\"], \n",
    "#          label=\"training accuracy\")\n",
    "# plt.plot(df[\"param_min_samples_split\"], \n",
    "#          df[\"mean_test_score\"], \n",
    "#          label=\"test accuracy\")\n",
    "# plt.xlabel(\"min_samples_split\")\n",
    "# plt.ylabel(\"Recall\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=12, max_features=6,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=5,\n",
       "            min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=900, n_jobs=None, oob_score=False, random_state=9,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf= RandomForestClassifier(max_depth=12, class_weight='balanced', n_estimators=900, max_features = 6, min_samples_split =10, random_state=9, min_samples_leaf = 5)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26216, 80)\n",
      "(26216,)\n",
      "(26216,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89     18818\n",
      "           1       0.73      0.74      0.73      7398\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     26216\n",
      "   macro avg       0.81      0.81      0.81     26216\n",
      "weighted avg       0.85      0.85      0.85     26216\n",
      "\n",
      "[[16751  2067]\n",
      " [ 1937  5461]]\n",
      "Score:  0.847268843454379\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "y_pred = rf.predict(X_train)\n",
    "\n",
    "\n",
    "# Evaluation train\n",
    "print(y_pred.shape)\n",
    "print(classification_report(y_train,y_pred))\n",
    "print(confusion_matrix(y_train,y_pred))\n",
    "print('Score: ', rf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11236,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89      8044\n",
      "           1       0.71      0.72      0.72      3192\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     11236\n",
      "   macro avg       0.80      0.80      0.80     11236\n",
      "weighted avg       0.84      0.84      0.84     11236\n",
      "\n",
      "[[7103  941]\n",
      " [ 889 2303]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluation validate\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(y_pred.shape)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABscAAAcyCAYAAADFSDuhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZHEsIiIiIiIiIiIiIiIiBo3/D1wj5RNSmPNyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 2160x2160 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imp=rf.feature_importances_\n",
    "names=X_train.columns.values\n",
    "imp,names=zip(*sorted(zip(imp,names)))\n",
    "\n",
    "df_1=pd.DataFrame({\"Variable\":names,\"importance\":imp})\n",
    "df_2 = df_1.sort_values(by=\"importance\",axis=0,ascending=False)\n",
    "df_2 = df_2.reset_index(drop=True)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(30, 30))\n",
    "\n",
    "ax = sns.barplot(x='Variable', y= 'importance', data=df_2[0:15])\n",
    "ax.set(xlabel = 'Top 15 Features', ylabel = 'Importance')\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:   50.4s\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 672 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1122 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed: 16.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get accuracy of 0.7293857823219759 using {'criterion': 'gini', 'max_depth': 14, 'max_features': 10, 'n_estimators': 900, 'oob_score': False}\n"
     ]
    }
   ],
   "source": [
    "# max_depth=10, class_weight='balanced', n_estimators=900, max_features = 12, min_samples_split =10, random_state=9, min_samples_leaf = 5\n",
    "# rf= RandomForestClassifier(max_depth=12, class_weight='balanced', n_estimators=900, max_features = 6, min_samples_split =10, random_state=9, min_samples_leaf = 5)\n",
    "#grid Search\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_depth': [10,12,14],\n",
    "    'n_estimators': [700,800,900,1000,1100], \n",
    "    'max_features': [4,6,8,10,12],\n",
    "    'criterion': ['gini','entropy'],\n",
    "    'oob_score': [True, False]}\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier(class_weight='balanced', min_samples_split= 10, min_samples_leaf = 5)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "clf = GridSearchCV(estimator = rf, param_grid = param_grid ,scoring='recall',\n",
    "                          cv = 5, verbose = 1, n_jobs=-1, refit = True)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "print('We can get accuracy of',clf.best_score_,'using',clf.best_params_)\n",
    "# We can get accuracy of 0.6803188306618462 using {'n_estimators': 800, 'max_features': 10, 'max_depth': 12} first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26216, 92)\n",
      "(26216,)\n",
      "(26216,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90     18818\n",
      "           1       0.74      0.76      0.75      7398\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     26216\n",
      "   macro avg       0.82      0.83      0.83     26216\n",
      "weighted avg       0.86      0.86      0.86     26216\n",
      "\n",
      "[[16880  1938]\n",
      " [ 1776  5622]]\n",
      "Score:  0.8583307903570339\n",
      "(11236,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89      8044\n",
      "           1       0.72      0.73      0.72      3192\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     11236\n",
      "   macro avg       0.80      0.81      0.81     11236\n",
      "weighted avg       0.84      0.84      0.84     11236\n",
      "\n",
      "[[7131  913]\n",
      " [ 868 2324]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8072847147705164"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf= RandomForestClassifier(n_estimators = 900, max_features = 10, class_weight='balanced', \n",
    "                           max_depth = 14, random_state=9, oob_score= False, min_samples_split= 10, min_samples_leaf = 5)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "y_pred = rf.predict(X_train)\n",
    "\n",
    "# Evaluation train\n",
    "print(y_pred.shape)\n",
    "print(classification_report(y_train,y_pred))\n",
    "print(confusion_matrix(y_train,y_pred))\n",
    "print('Score: ', rf.score(X_train, y_train))\n",
    "\n",
    "# Evaluation validate\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(y_pred.shape)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True False  True  True  True  True False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False  True  True False  True  True False  True  True False  True  True\n",
      "  True False  True  True  True  True  True  True False False  True  True\n",
      "  True False  True  True  True  True  True False  True  True  True  True\n",
      "  True False False  True  True  True  True False  True  True  True  True\n",
      "  True  True  True  True  True False  True  True False False False False\n",
      " False False False False False False False False]\n",
      "[41  1  1 43  1  1  1  1 13 30 38 19 18  3 23 22 14 15 17 10  1  2  9  8\n",
      " 34  1  1  7  1  1 39  1  1 40  1  1  1 33  1  1  1  1  1  1  6  4  1  1\n",
      "  1  5  1  1  1  1  1 42  1  1  1  1  1 35 36  1  1  1  1 32  1  1  1  1\n",
      "  1  1  1  1  1 11  1  1 20 37 31 27 26 12 29 28 21 24 25 16]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['listed_presence', 'clm_tot_chrg_amt_v2_norm_log',\n",
       "       'mem_age_bin_(0.0, 20.0]', 'mem_age_bin_(20.0, 45.0]',\n",
       "       'mem_age_bin_(45.0, 60.0]', 'mem_age_bin_(60.0, 146.0]',\n",
       "       'pos_denied_prcnt_grp_G0-15', 'pos_denied_prcnt_grp_Others_Low',\n",
       "       'lob_denied_prcnt_grp_G0-20', 'lob_denied_prcnt_grp_G30-50',\n",
       "       'lob_denied_prcnt_grp_G50-100', 'collect_set_denied_prcnt_grp_G20-30',\n",
       "       'collect_set_denied_prcnt_grp_G30-50', 'cpt_denied_prcnt_grp_G0-05',\n",
       "       'cpt_denied_prcnt_grp_G05-10', 'cpt_denied_prcnt_grp_G10-20',\n",
       "       'cpt_denied_prcnt_grp_G40-60', 'cpt_denied_prcnt_grp_G60-100',\n",
       "       'cpt_denied_prcnt_grp_Others_High', 'cpt_denied_prcnt_grp_Others_Low',\n",
       "       'tin_denied_prcnt_grp_G0', 'tin_denied_prcnt_grp_G0-05',\n",
       "       'tin_denied_prcnt_grp_G30-60', 'tin_denied_prcnt_grp_G60-100',\n",
       "       'tin_denied_prcnt_grp_Others_High', 'state_denied_prcnt_grp_G0-15',\n",
       "       'state_denied_prcnt_grp_G15-25', 'state_denied_prcnt_grp_G25-30',\n",
       "       'state_denied_prcnt_grp_G30-50', 'state_denied_prcnt_grp_G50-100',\n",
       "       'state_denied_prcnt_grp_Others_Low', 'diag_denied_prcnt_grp_G0-15',\n",
       "       'diag_denied_prcnt_grp_G15-25', 'diag_denied_prcnt_grp_G25-30',\n",
       "       'diag_denied_prcnt_grp_G30-55', 'diag_denied_prcnt_grp_Others_High',\n",
       "       'diag_denied_prcnt_grp_Others_Low', 'npi_denied_prcnt_grp_G0',\n",
       "       'npi_denied_prcnt_grp_G0-15', 'npi_denied_prcnt_grp_G40-70',\n",
       "       'npi_denied_prcnt_grp_G70-90', 'npi_denied_prcnt_grp_G90-100',\n",
       "       'npi_denied_prcnt_grp_Others_High', 'npi_denied_prcnt_grp_Others_Low',\n",
       "       'policy_denied_prcnt_grp_G0', 'policy_denied_prcnt_grp_G0-20',\n",
       "       'policy_denied_prcnt_grp_G20-30', 'policy_denied_prcnt_grp_G30-50',\n",
       "       'policy_denied_prcnt_grp_Others_High',\n",
       "       'policy_denied_prcnt_grp_Others_Low'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(class_weight='balanced')\n",
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(logreg, 50)       \n",
    "rfe = rfe.fit(X_train,y_train)\n",
    "print(rfe.support_)           # Printing the boolean results\n",
    "print(rfe.ranking_)           # Printing the ranking\n",
    "col = X_train.columns[rfe.support_]\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rollup=train_input_dummy.groupby(['icn', 'clm_den_flag'],as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_imp=pd.read_csv(\"/mapr/projects/MCR_Threshold/Data/dummy_imp_dev.csv\")\n",
    "# name = df_2[df_2[\"cum_per\"]<=80][\"Variable\"]\n",
    "\n",
    "#name=np.append(name, ['mcr_denial_flag'])\n",
    "# name=np.append(col, ['clm_den_flag'])\n",
    "\n",
    "# train_rollup=train_input_dummy.groupby(['icn', 'clm_den_flag'],as_index=False).sum()\n",
    "\n",
    "# train_rollup=train_rollup[name]\n",
    "X=train_rollup.drop('clm_den_flag',axis=1).values\n",
    "X.shape\n",
    "y=train_rollup['clm_den_flag'].values\n",
    "y.shape\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rollup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf= RandomForestClassifier(n_estimators = 1400, max_features = 8, class_weight='balanced', max_depth = 12, random_state=9, oob_score= True, min_samples_split= 6, min_samples_leaf = 3)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "y_pred = rf.predict(X_train)\n",
    "\n",
    "\n",
    "# Evaluation train\n",
    "print(y_pred.shape)\n",
    "print(classification_report(y_train,y_pred))\n",
    "print(confusion_matrix(y_train,y_pred))\n",
    "print('Score: ', rf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation validate\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(y_pred.shape)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lift Decile analysis\n",
    "\n",
    "y_pred_prob_1 = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "data_n=pd.DataFrame({\"actual\":y_test,\"pred\":y_pred_prob_1})\n",
    "# data_lift_analysis=data_n.copy()\n",
    "#data_lift_analysis.to_csv(\"/mapr/projects/MCR_Threshold/Data/lift_all_inscope_decide1.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying threshold In sample Validation\n",
    "\n",
    "\n",
    "threshold=0.3\n",
    "\n",
    "c=[]\n",
    "\n",
    "for i in data_n['pred']:\n",
    "    \n",
    "    if i > threshold:\n",
    "        d=[1]\n",
    "        c.extend(d)\n",
    "      \n",
    "    else:\n",
    "        d=[0]\n",
    "        c.extend(d)\n",
    "        \n",
    "data_n['pred1']=c\n",
    "\n",
    "\n",
    "# Print confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print (confusion_matrix(data_n['actual'], data_n['pred1']))\n",
    "print(classification_report(data_n['actual'], data_n['pred1']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old with 71 and 69\n",
    "# rf= RandomForestClassifier(n_estimators = 1400, max_features = 8, class_weight='balanced', max_depth = 12, random_state=9, oob_score= True, min_samples_split= 6, min_samples_leaf = 3)\n",
    "\n",
    "# new with 69 and 68\n",
    "rf= RandomForestClassifier(max_depth=10, class_weight='balanced', n_estimators=900, max_features = 12, min_samples_split =12, random_state=9, min_samples_leaf = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random grid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_depth': [8,10,12],\n",
    "    'n_estimators': [700,800,900,1000,1100], \n",
    "    'max_features': [8,10,12,14,16],\n",
    "    'criterion': ['gini','entropy']}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier(class_weight='balanced', min_samples_split= 12, min_samples_leaf = 6)\n",
    "# Instantiate the grid search model\n",
    "clf = GridSearchCV(estimator = rf, param_grid = param_grid ,scoring='recall',\n",
    "                          cv = 5, verbose = 1, n_jobs=-1, refit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We can get accuracy of',clf.best_score_,'using',clf.best_params_)\n",
    "\n",
    "# We can get accuracy of 0.6803188306618462 using {'n_estimators': 800, 'max_features': 10, 'max_depth': 12} first\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf= RandomForestClassifier(n_estimators = 700, max_features = 16, class_weight='balanced', max_depth = 12, random_state=9, oob_score= True, min_samples_split= 12, min_samples_leaf = 6)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "y_pred = rf.predict(X_train)\n",
    "\n",
    "\n",
    "# Evaluation train\n",
    "print(y_pred.shape)\n",
    "print(classification_report(y_train,y_pred))\n",
    "print(confusion_matrix(y_train,y_pred))\n",
    "print('Score: ', rf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation validate\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(y_pred.shape)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rollup\n",
    "test_rollup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_191\"; OpenJDK Runtime Environment (build 1.8.0_191-8u191-b12-2ubuntu0.16.04.1-b12); OpenJDK 64-Bit Server VM (build 25.191-b12, mixed mode)\n",
      "  Starting server from /opt/conda/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpdpys5cjs\n",
      "  JVM stdout: /tmp/tmpdpys5cjs/h2o_unknownUser_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpdpys5cjs/h2o_unknownUser_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n",
      "Warning: Your H2O cluster version is too old (4 months and 2 days)! Please download and install the latest version from http://h2o.ai/download/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.24.0.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>4 months and 2 days !!!</td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_unknownUser_licfa2</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>11.56 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>64</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>64</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.8 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------\n",
       "H2O cluster uptime:         01 secs\n",
       "H2O cluster timezone:       Etc/UTC\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.24.0.2\n",
       "H2O cluster version age:    4 months and 2 days !!!\n",
       "H2O cluster name:           H2O_from_python_unknownUser_licfa2\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    11.56 Gb\n",
       "H2O cluster total cores:    64\n",
       "H2O cluster allowed cores:  64\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.8 final\n",
       "--------------------------  ---------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#h2o.shutdown(prompt=False)\n",
    "h2o.init(nthreads = -1, max_mem_size = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subst=[]\n",
    "train_rollup1=train_rollup[subset]\n",
    "test_rollup1=test_rollup[subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "train_hex=h2o.H2OFrame(train_rollup)\n",
    "test_hex=h2o.H2OFrame(test_rollup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hex['clm_den_flag']=train_hex['clm_den_flag'].asfactor()\n",
    "test_hex['clm_den_flag']=test_hex['clm_den_flag'].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a seed will guarantee reproducibility\n",
    "\n",
    "splits = train_hex.split_frame(ratios=[0.7], seed=1)  \n",
    "\n",
    "train = splits[0]\n",
    "valid = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 'clm_den_flag'\n",
    "x = list(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import H2O RF:\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "rf_fit2 = H2ORandomForestEstimator(model_id='rf_fit2', ntrees=200,balance_classes=True, seed=1)\n",
    "rf_fit2.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.13016386847960307\n",
      "RMSE: 0.3607823006739702\n",
      "LogLoss: 0.41161192213290415\n",
      "Mean Per-Class Error: 0.21136421804784877\n",
      "AUC: 0.8631906431622982\n",
      "pr_auc: 0.7396624144278136\n",
      "Gini: 0.7263812863245964\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2259896297581175: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>6768.0</td>\n",
       "<td>1174.0</td>\n",
       "<td>0.1478</td>\n",
       "<td> (1174.0/7942.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>888.0</td>\n",
       "<td>2294.0</td>\n",
       "<td>0.2791</td>\n",
       "<td> (888.0/3182.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>7656.0</td>\n",
       "<td>3468.0</td>\n",
       "<td>0.1854</td>\n",
       "<td> (2062.0/11124.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0     1     Error    Rate\n",
       "-----  ----  ----  -------  ----------------\n",
       "0      6768  1174  0.1478   (1174.0/7942.0)\n",
       "1      888   2294  0.2791   (888.0/3182.0)\n",
       "Total  7656  3468  0.1854   (2062.0/11124.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.2259896</td>\n",
       "<td>0.6899248</td>\n",
       "<td>245.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1195683</td>\n",
       "<td>0.7601931</td>\n",
       "<td>308.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.4790757</td>\n",
       "<td>0.7157876</td>\n",
       "<td>157.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3426445</td>\n",
       "<td>0.8286588</td>\n",
       "<td>200.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9860516</td>\n",
       "<td>0.9886364</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0003198</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9989110</td>\n",
       "<td>0.9998741</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2964025</td>\n",
       "<td>0.5635105</td>\n",
       "<td>216.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1773573</td>\n",
       "<td>0.7831552</td>\n",
       "<td>271.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2008331</td>\n",
       "<td>0.7886358</td>\n",
       "<td>258.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.22599      0.689925  245\n",
       "max f2                       0.119568     0.760193  308\n",
       "max f0point5                 0.479076     0.715788  157\n",
       "max accuracy                 0.342644     0.828659  200\n",
       "max precision                0.986052     0.988636  3\n",
       "max recall                   0.000319835  1         399\n",
       "max specificity              0.998911     0.999874  0\n",
       "max absolute_mcc             0.296403     0.56351   216\n",
       "max min_per_class_accuracy   0.177357     0.783155  271\n",
       "max mean_per_class_accuracy  0.200833     0.788636  258"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 28.60 %, avg score: 23.86 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100683</td>\n",
       "<td>0.9799944</td>\n",
       "<td>3.4334875</td>\n",
       "<td>3.4334875</td>\n",
       "<td>0.9821429</td>\n",
       "<td>0.9911372</td>\n",
       "<td>0.9821429</td>\n",
       "<td>0.9911372</td>\n",
       "<td>0.0345695</td>\n",
       "<td>0.0345695</td>\n",
       "<td>243.3487474</td>\n",
       "<td>243.3487474</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200467</td>\n",
       "<td>0.9431405</td>\n",
       "<td>3.2124620</td>\n",
       "<td>3.3234703</td>\n",
       "<td>0.9189189</td>\n",
       "<td>0.9614565</td>\n",
       "<td>0.9506726</td>\n",
       "<td>0.9763634</td>\n",
       "<td>0.0320553</td>\n",
       "<td>0.0666248</td>\n",
       "<td>221.2461991</td>\n",
       "<td>232.3470305</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300252</td>\n",
       "<td>0.9123608</td>\n",
       "<td>3.3069462</td>\n",
       "<td>3.3179788</td>\n",
       "<td>0.9459459</td>\n",
       "<td>0.9272703</td>\n",
       "<td>0.9491018</td>\n",
       "<td>0.9600480</td>\n",
       "<td>0.0329981</td>\n",
       "<td>0.0996229</td>\n",
       "<td>230.6946167</td>\n",
       "<td>231.7978750</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400036</td>\n",
       "<td>0.8784967</td>\n",
       "<td>3.1179778</td>\n",
       "<td>3.2680909</td>\n",
       "<td>0.8918919</td>\n",
       "<td>0.8941748</td>\n",
       "<td>0.9348315</td>\n",
       "<td>0.9436167</td>\n",
       "<td>0.0311125</td>\n",
       "<td>0.1307354</td>\n",
       "<td>211.7977814</td>\n",
       "<td>226.8090876</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500719</td>\n",
       "<td>0.8465049</td>\n",
       "<td>3.0901387</td>\n",
       "<td>3.2323088</td>\n",
       "<td>0.8839286</td>\n",
       "<td>0.8620845</td>\n",
       "<td>0.9245961</td>\n",
       "<td>0.9272225</td>\n",
       "<td>0.0311125</td>\n",
       "<td>0.1618479</td>\n",
       "<td>209.0138727</td>\n",
       "<td>223.2308757</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000539</td>\n",
       "<td>0.7064992</td>\n",
       "<td>2.9300291</td>\n",
       "<td>3.0813047</td>\n",
       "<td>0.8381295</td>\n",
       "<td>0.7733867</td>\n",
       "<td>0.8814016</td>\n",
       "<td>0.8503737</td>\n",
       "<td>0.1464488</td>\n",
       "<td>0.3082967</td>\n",
       "<td>193.0029075</td>\n",
       "<td>208.1304711</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500360</td>\n",
       "<td>0.5676798</td>\n",
       "<td>2.4898960</td>\n",
       "<td>2.8842866</td>\n",
       "<td>0.7122302</td>\n",
       "<td>0.6401571</td>\n",
       "<td>0.8250449</td>\n",
       "<td>0.7803435</td>\n",
       "<td>0.1244500</td>\n",
       "<td>0.4327467</td>\n",
       "<td>148.9895953</td>\n",
       "<td>188.4286575</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000180</td>\n",
       "<td>0.4379139</td>\n",
       "<td>2.1692275</td>\n",
       "<td>2.7056022</td>\n",
       "<td>0.6205036</td>\n",
       "<td>0.5021313</td>\n",
       "<td>0.7739326</td>\n",
       "<td>0.7108217</td>\n",
       "<td>0.1084224</td>\n",
       "<td>0.5411691</td>\n",
       "<td>116.9227534</td>\n",
       "<td>170.5602158</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2999820</td>\n",
       "<td>0.2343501</td>\n",
       "<td>1.6190611</td>\n",
       "<td>2.3435304</td>\n",
       "<td>0.4631295</td>\n",
       "<td>0.3156897</td>\n",
       "<td>0.6703626</td>\n",
       "<td>0.5791505</td>\n",
       "<td>0.1618479</td>\n",
       "<td>0.7030170</td>\n",
       "<td>61.9061131</td>\n",
       "<td>134.3530350</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000360</td>\n",
       "<td>0.1664695</td>\n",
       "<td>0.9485770</td>\n",
       "<td>1.9946353</td>\n",
       "<td>0.2713387</td>\n",
       "<td>0.1962845</td>\n",
       "<td>0.5705618</td>\n",
       "<td>0.4833910</td>\n",
       "<td>0.0949089</td>\n",
       "<td>0.7979258</td>\n",
       "<td>-5.1423015</td>\n",
       "<td>99.4635273</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.1296845</td>\n",
       "<td>0.7387949</td>\n",
       "<td>1.7435575</td>\n",
       "<td>0.2113309</td>\n",
       "<td>0.1469320</td>\n",
       "<td>0.4987415</td>\n",
       "<td>0.4161234</td>\n",
       "<td>0.0738529</td>\n",
       "<td>0.8717788</td>\n",
       "<td>-26.1205115</td>\n",
       "<td>74.3557511</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999640</td>\n",
       "<td>0.0986279</td>\n",
       "<td>0.4747150</td>\n",
       "<td>1.5321471</td>\n",
       "<td>0.1357914</td>\n",
       "<td>0.1134491</td>\n",
       "<td>0.4382679</td>\n",
       "<td>0.3656928</td>\n",
       "<td>0.0474544</td>\n",
       "<td>0.9192332</td>\n",
       "<td>-52.5284989</td>\n",
       "<td>53.2147133</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000180</td>\n",
       "<td>0.0717944</td>\n",
       "<td>0.3046754</td>\n",
       "<td>1.3567040</td>\n",
       "<td>0.0871518</td>\n",
       "<td>0.0850557</td>\n",
       "<td>0.3880827</td>\n",
       "<td>0.3255812</td>\n",
       "<td>0.0304840</td>\n",
       "<td>0.9497172</td>\n",
       "<td>-69.5324611</td>\n",
       "<td>35.6703952</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999820</td>\n",
       "<td>0.0472175</td>\n",
       "<td>0.2672237</td>\n",
       "<td>1.2205648</td>\n",
       "<td>0.0764388</td>\n",
       "<td>0.0592018</td>\n",
       "<td>0.3491404</td>\n",
       "<td>0.2922950</td>\n",
       "<td>0.0267128</td>\n",
       "<td>0.9764299</td>\n",
       "<td>-73.2776318</td>\n",
       "<td>22.0564829</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999461</td>\n",
       "<td>0.0243143</td>\n",
       "<td>0.1571904</td>\n",
       "<td>1.1024475</td>\n",
       "<td>0.0449640</td>\n",
       "<td>0.0359570</td>\n",
       "<td>0.3153531</td>\n",
       "<td>0.2638215</td>\n",
       "<td>0.0157134</td>\n",
       "<td>0.9921433</td>\n",
       "<td>-84.2809599</td>\n",
       "<td>10.2447521</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0785246</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0224618</td>\n",
       "<td>0.0119675</td>\n",
       "<td>0.2860482</td>\n",
       "<td>0.2386225</td>\n",
       "<td>0.0078567</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.1475415</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100683                   0.979994           3.43349    3.43349            0.982143         0.991137   0.982143                    0.991137            0.0345695       0.0345695                  243.349   243.349\n",
       "    2        0.0200467                   0.94314            3.21246    3.32347            0.918919         0.961456   0.950673                    0.976363            0.0320553       0.0666248                  221.246   232.347\n",
       "    3        0.0300252                   0.912361           3.30695    3.31798            0.945946         0.92727    0.949102                    0.960048            0.0329981       0.0996229                  230.695   231.798\n",
       "    4        0.0400036                   0.878497           3.11798    3.26809            0.891892         0.894175   0.934831                    0.943617            0.0311125       0.130735                   211.798   226.809\n",
       "    5        0.0500719                   0.846505           3.09014    3.23231            0.883929         0.862085   0.924596                    0.927222            0.0311125       0.161848                   209.014   223.231\n",
       "    6        0.100054                    0.706499           2.93003    3.0813             0.838129         0.773387   0.881402                    0.850374            0.146449        0.308297                   193.003   208.13\n",
       "    7        0.150036                    0.56768            2.4899     2.88429            0.71223          0.640157   0.825045                    0.780343            0.12445         0.432747                   148.99    188.429\n",
       "    8        0.200018                    0.437914           2.16923    2.7056             0.620504         0.502131   0.773933                    0.710822            0.108422        0.541169                   116.923   170.56\n",
       "    9        0.299982                    0.23435            1.61906    2.34353            0.463129         0.31569    0.670363                    0.579151            0.161848        0.703017                   61.9061   134.353\n",
       "    10       0.400036                    0.16647            0.948577   1.99464            0.271339         0.196284   0.570562                    0.483391            0.0949089       0.797926                   -5.1423   99.4635\n",
       "    11       0.5                         0.129684           0.738795   1.74356            0.211331         0.146932   0.498741                    0.416123            0.0738529       0.871779                   -26.1205  74.3558\n",
       "    12       0.599964                    0.0986279          0.474715   1.53215            0.135791         0.113449   0.438268                    0.365693            0.0474544       0.919233                   -52.5285  53.2147\n",
       "    13       0.700018                    0.0717944          0.304675   1.3567             0.0871518        0.0850557  0.388083                    0.325581            0.030484        0.949717                   -69.5325  35.6704\n",
       "    14       0.799982                    0.0472175          0.267224   1.22056            0.0764388        0.0592018  0.34914                     0.292295            0.0267128       0.97643                    -73.2776  22.0565\n",
       "    15       0.899946                    0.0243143          0.15719    1.10245            0.044964         0.035957   0.315353                    0.263822            0.0157134       0.992143                   -84.281   10.2448\n",
       "    16       1                           0                  0.0785246  1                  0.0224618        0.0119675  0.286048                    0.238623            0.00785669      1                          -92.1475  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_perf2 = rf_fit2.model_performance(valid)\n",
    "print(rf_perf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# varimp_rf=rf_fit2.varimp(True)\n",
    "# varimp_rf.to_csv(\"/projects/G12/pickle_data/varimp_rf.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tin_denied_prcnt_grp_G60-100</td>\n",
       "      <td>53013.746094</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.056414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bil_diff_fst_norm_log</td>\n",
       "      <td>47340.835938</td>\n",
       "      <td>0.892992</td>\n",
       "      <td>0.050377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diag_amnt_avg</td>\n",
       "      <td>43088.406250</td>\n",
       "      <td>0.812778</td>\n",
       "      <td>0.045852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>icn</td>\n",
       "      <td>39892.019531</td>\n",
       "      <td>0.752484</td>\n",
       "      <td>0.042451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cpt_denied_prcnt_grp_G60-100</td>\n",
       "      <td>39664.433594</td>\n",
       "      <td>0.748191</td>\n",
       "      <td>0.042209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>npi_denied_prcnt_grp_G40-70</td>\n",
       "      <td>36448.957031</td>\n",
       "      <td>0.687538</td>\n",
       "      <td>0.038787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>npi_denied_prcnt_grp_G0-15</td>\n",
       "      <td>35743.472656</td>\n",
       "      <td>0.674230</td>\n",
       "      <td>0.038036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>unit_agg_norm_log</td>\n",
       "      <td>29832.748047</td>\n",
       "      <td>0.562736</td>\n",
       "      <td>0.031746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>npi_diag_amnt_avg</td>\n",
       "      <td>27693.304688</td>\n",
       "      <td>0.522380</td>\n",
       "      <td>0.029470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tin_diag_amnt_avg</td>\n",
       "      <td>27328.062500</td>\n",
       "      <td>0.515490</td>\n",
       "      <td>0.029081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>clm_tot_chrg_amt_v2_norm_log</td>\n",
       "      <td>26238.722656</td>\n",
       "      <td>0.494942</td>\n",
       "      <td>0.027922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>diag_denied_prcnt_grp_G0-15</td>\n",
       "      <td>20853.154297</td>\n",
       "      <td>0.393354</td>\n",
       "      <td>0.022191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>collect_set_denied_prcnt_grp_G0-20</td>\n",
       "      <td>18920.851562</td>\n",
       "      <td>0.356905</td>\n",
       "      <td>0.020135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>collect_set_denied_prcnt_grp_G50-100</td>\n",
       "      <td>16506.525391</td>\n",
       "      <td>0.311363</td>\n",
       "      <td>0.017565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tin_denied_prcnt_grp_G30-60</td>\n",
       "      <td>15631.319336</td>\n",
       "      <td>0.294854</td>\n",
       "      <td>0.016634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cpt_denied_prcnt_grp_G20-40</td>\n",
       "      <td>14014.965820</td>\n",
       "      <td>0.264365</td>\n",
       "      <td>0.014914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tin_denied_prcnt_grp_G05-20</td>\n",
       "      <td>11940.037109</td>\n",
       "      <td>0.225225</td>\n",
       "      <td>0.012706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>npi_denied_prcnt_grp_G0</td>\n",
       "      <td>11106.749023</td>\n",
       "      <td>0.209507</td>\n",
       "      <td>0.011819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cpt_denied_prcnt_grp_G40-60</td>\n",
       "      <td>10779.620117</td>\n",
       "      <td>0.203336</td>\n",
       "      <td>0.011471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>diag_denied_prcnt_grp_G75-100</td>\n",
       "      <td>10474.530273</td>\n",
       "      <td>0.197581</td>\n",
       "      <td>0.011146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cpt_denied_prcnt_grp_G05-10</td>\n",
       "      <td>9994.352539</td>\n",
       "      <td>0.188524</td>\n",
       "      <td>0.010635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>lob_denied_prcnt_grp_G30-50</td>\n",
       "      <td>9301.678711</td>\n",
       "      <td>0.175458</td>\n",
       "      <td>0.009898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>npi_denied_prcnt_grp_G15-40</td>\n",
       "      <td>9173.753906</td>\n",
       "      <td>0.173045</td>\n",
       "      <td>0.009762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>lob_denied_prcnt_grp_G20-30</td>\n",
       "      <td>9053.647461</td>\n",
       "      <td>0.170779</td>\n",
       "      <td>0.009634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cpt_denied_prcnt_grp_Others</td>\n",
       "      <td>8740.526367</td>\n",
       "      <td>0.164873</td>\n",
       "      <td>0.009301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>policy_denied_prcnt_grp_G30-50</td>\n",
       "      <td>8710.309570</td>\n",
       "      <td>0.164303</td>\n",
       "      <td>0.009269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mem_age_bin_(45.0, 60.0]</td>\n",
       "      <td>8333.568359</td>\n",
       "      <td>0.157196</td>\n",
       "      <td>0.008868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>diag_denied_prcnt_grp_G30-55</td>\n",
       "      <td>8217.841797</td>\n",
       "      <td>0.155013</td>\n",
       "      <td>0.008745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>mem_age_bin_(20.0, 45.0]</td>\n",
       "      <td>8140.684570</td>\n",
       "      <td>0.153558</td>\n",
       "      <td>0.008663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>diag_denied_prcnt_grp_G55-75</td>\n",
       "      <td>8103.965820</td>\n",
       "      <td>0.152865</td>\n",
       "      <td>0.008624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>st_abbr_cd_bin_TX</td>\n",
       "      <td>4380.041992</td>\n",
       "      <td>0.082621</td>\n",
       "      <td>0.004661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>collect_set_denied_prcnt_grp_G20-30</td>\n",
       "      <td>3771.152832</td>\n",
       "      <td>0.071135</td>\n",
       "      <td>0.004013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>bil_diff_fst_bin_(90.0, 180.0]</td>\n",
       "      <td>3626.624756</td>\n",
       "      <td>0.068409</td>\n",
       "      <td>0.003859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>tin_denied_prcnt_grp_G0</td>\n",
       "      <td>3407.049072</td>\n",
       "      <td>0.064267</td>\n",
       "      <td>0.003626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>bil_diff_fst_bin_(180.0, 983.0]</td>\n",
       "      <td>3067.690918</td>\n",
       "      <td>0.057866</td>\n",
       "      <td>0.003264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>st_abbr_cd_bin_AZ</td>\n",
       "      <td>3002.164062</td>\n",
       "      <td>0.056630</td>\n",
       "      <td>0.003195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>lob_denied_prcnt_grp_G0-20</td>\n",
       "      <td>2981.369873</td>\n",
       "      <td>0.056238</td>\n",
       "      <td>0.003173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>dmg_pat_sex_G15-45</td>\n",
       "      <td>2705.353516</td>\n",
       "      <td>0.051031</td>\n",
       "      <td>0.002879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>st_abbr_cd_bin_NY</td>\n",
       "      <td>2596.530518</td>\n",
       "      <td>0.048978</td>\n",
       "      <td>0.002763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>st_abbr_cd_bin_IL</td>\n",
       "      <td>2557.097656</td>\n",
       "      <td>0.048235</td>\n",
       "      <td>0.002721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>plc_of_srvc_bin_15</td>\n",
       "      <td>2409.045410</td>\n",
       "      <td>0.045442</td>\n",
       "      <td>0.002564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>dmg_pat_sex_G70-100</td>\n",
       "      <td>2241.843750</td>\n",
       "      <td>0.042288</td>\n",
       "      <td>0.002386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>policy_denied_prcnt_grp_G50-100</td>\n",
       "      <td>2206.801514</td>\n",
       "      <td>0.041627</td>\n",
       "      <td>0.002348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>pos_denied_prcnt_grp_G15-45</td>\n",
       "      <td>2152.788574</td>\n",
       "      <td>0.040608</td>\n",
       "      <td>0.002291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>st_abbr_cd_bin_WI</td>\n",
       "      <td>1911.129150</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>0.002034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>collect_set_denied_prcnt_grp_G30-50</td>\n",
       "      <td>1678.357300</td>\n",
       "      <td>0.031659</td>\n",
       "      <td>0.001786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>st_abbr_cd_bin_OH</td>\n",
       "      <td>1616.352539</td>\n",
       "      <td>0.030489</td>\n",
       "      <td>0.001720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>lob_denied_prcnt_grp_G50-100</td>\n",
       "      <td>1273.649170</td>\n",
       "      <td>0.024025</td>\n",
       "      <td>0.001355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>st_abbr_cd_bin_NJ</td>\n",
       "      <td>1154.267456</td>\n",
       "      <td>0.021773</td>\n",
       "      <td>0.001228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>state_denied_prcnt_grp_G50-100</td>\n",
       "      <td>740.527039</td>\n",
       "      <td>0.013969</td>\n",
       "      <td>0.000788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>dmg_pat_sex_G0-15</td>\n",
       "      <td>623.593140</td>\n",
       "      <td>0.011763</td>\n",
       "      <td>0.000664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>pos_denied_prcnt_grp_G45-70</td>\n",
       "      <td>498.779968</td>\n",
       "      <td>0.009409</td>\n",
       "      <td>0.000531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>st_abbr_cd_bin_OK</td>\n",
       "      <td>486.455383</td>\n",
       "      <td>0.009176</td>\n",
       "      <td>0.000518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>dmg_pat_sex_G45-70</td>\n",
       "      <td>438.343903</td>\n",
       "      <td>0.008268</td>\n",
       "      <td>0.000466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>pos_denied_prcnt_grp_G0-15</td>\n",
       "      <td>419.423645</td>\n",
       "      <td>0.007912</td>\n",
       "      <td>0.000446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>pos_denied_prcnt_grp_Others</td>\n",
       "      <td>344.684509</td>\n",
       "      <td>0.006502</td>\n",
       "      <td>0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>dmg_pat_sex_Others_Low</td>\n",
       "      <td>313.447784</td>\n",
       "      <td>0.005913</td>\n",
       "      <td>0.000334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>state_denied_prcnt_grp_Others</td>\n",
       "      <td>302.959595</td>\n",
       "      <td>0.005715</td>\n",
       "      <td>0.000322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>policy_denied_prcnt_grp_G0</td>\n",
       "      <td>104.921379</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.000112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>dmg_pat_sex_Others</td>\n",
       "      <td>29.407291</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 variable  relative_importance  \\\n",
       "0            tin_denied_prcnt_grp_G60-100         53013.746094   \n",
       "1                   bil_diff_fst_norm_log         47340.835938   \n",
       "2                           diag_amnt_avg         43088.406250   \n",
       "3                                     icn         39892.019531   \n",
       "4            cpt_denied_prcnt_grp_G60-100         39664.433594   \n",
       "5             npi_denied_prcnt_grp_G40-70         36448.957031   \n",
       "6              npi_denied_prcnt_grp_G0-15         35743.472656   \n",
       "7                       unit_agg_norm_log         29832.748047   \n",
       "8                       npi_diag_amnt_avg         27693.304688   \n",
       "9                       tin_diag_amnt_avg         27328.062500   \n",
       "10           clm_tot_chrg_amt_v2_norm_log         26238.722656   \n",
       "11            diag_denied_prcnt_grp_G0-15         20853.154297   \n",
       "12     collect_set_denied_prcnt_grp_G0-20         18920.851562   \n",
       "13   collect_set_denied_prcnt_grp_G50-100         16506.525391   \n",
       "14            tin_denied_prcnt_grp_G30-60         15631.319336   \n",
       "15            cpt_denied_prcnt_grp_G20-40         14014.965820   \n",
       "16            tin_denied_prcnt_grp_G05-20         11940.037109   \n",
       "17                npi_denied_prcnt_grp_G0         11106.749023   \n",
       "18            cpt_denied_prcnt_grp_G40-60         10779.620117   \n",
       "19          diag_denied_prcnt_grp_G75-100         10474.530273   \n",
       "20            cpt_denied_prcnt_grp_G05-10          9994.352539   \n",
       "21            lob_denied_prcnt_grp_G30-50          9301.678711   \n",
       "22            npi_denied_prcnt_grp_G15-40          9173.753906   \n",
       "23            lob_denied_prcnt_grp_G20-30          9053.647461   \n",
       "24            cpt_denied_prcnt_grp_Others          8740.526367   \n",
       "25         policy_denied_prcnt_grp_G30-50          8710.309570   \n",
       "26               mem_age_bin_(45.0, 60.0]          8333.568359   \n",
       "27           diag_denied_prcnt_grp_G30-55          8217.841797   \n",
       "28               mem_age_bin_(20.0, 45.0]          8140.684570   \n",
       "29           diag_denied_prcnt_grp_G55-75          8103.965820   \n",
       "..                                    ...                  ...   \n",
       "74                      st_abbr_cd_bin_TX          4380.041992   \n",
       "75    collect_set_denied_prcnt_grp_G20-30          3771.152832   \n",
       "76         bil_diff_fst_bin_(90.0, 180.0]          3626.624756   \n",
       "77                tin_denied_prcnt_grp_G0          3407.049072   \n",
       "78        bil_diff_fst_bin_(180.0, 983.0]          3067.690918   \n",
       "79                      st_abbr_cd_bin_AZ          3002.164062   \n",
       "80             lob_denied_prcnt_grp_G0-20          2981.369873   \n",
       "81                     dmg_pat_sex_G15-45          2705.353516   \n",
       "82                      st_abbr_cd_bin_NY          2596.530518   \n",
       "83                      st_abbr_cd_bin_IL          2557.097656   \n",
       "84                     plc_of_srvc_bin_15          2409.045410   \n",
       "85                    dmg_pat_sex_G70-100          2241.843750   \n",
       "86        policy_denied_prcnt_grp_G50-100          2206.801514   \n",
       "87            pos_denied_prcnt_grp_G15-45          2152.788574   \n",
       "88                      st_abbr_cd_bin_WI          1911.129150   \n",
       "89    collect_set_denied_prcnt_grp_G30-50          1678.357300   \n",
       "90                      st_abbr_cd_bin_OH          1616.352539   \n",
       "91           lob_denied_prcnt_grp_G50-100          1273.649170   \n",
       "92                      st_abbr_cd_bin_NJ          1154.267456   \n",
       "93         state_denied_prcnt_grp_G50-100           740.527039   \n",
       "94                      dmg_pat_sex_G0-15           623.593140   \n",
       "95            pos_denied_prcnt_grp_G45-70           498.779968   \n",
       "96                      st_abbr_cd_bin_OK           486.455383   \n",
       "97                     dmg_pat_sex_G45-70           438.343903   \n",
       "98             pos_denied_prcnt_grp_G0-15           419.423645   \n",
       "99            pos_denied_prcnt_grp_Others           344.684509   \n",
       "100                dmg_pat_sex_Others_Low           313.447784   \n",
       "101         state_denied_prcnt_grp_Others           302.959595   \n",
       "102            policy_denied_prcnt_grp_G0           104.921379   \n",
       "103                    dmg_pat_sex_Others            29.407291   \n",
       "\n",
       "     scaled_importance  percentage  \n",
       "0             1.000000    0.056414  \n",
       "1             0.892992    0.050377  \n",
       "2             0.812778    0.045852  \n",
       "3             0.752484    0.042451  \n",
       "4             0.748191    0.042209  \n",
       "5             0.687538    0.038787  \n",
       "6             0.674230    0.038036  \n",
       "7             0.562736    0.031746  \n",
       "8             0.522380    0.029470  \n",
       "9             0.515490    0.029081  \n",
       "10            0.494942    0.027922  \n",
       "11            0.393354    0.022191  \n",
       "12            0.356905    0.020135  \n",
       "13            0.311363    0.017565  \n",
       "14            0.294854    0.016634  \n",
       "15            0.264365    0.014914  \n",
       "16            0.225225    0.012706  \n",
       "17            0.209507    0.011819  \n",
       "18            0.203336    0.011471  \n",
       "19            0.197581    0.011146  \n",
       "20            0.188524    0.010635  \n",
       "21            0.175458    0.009898  \n",
       "22            0.173045    0.009762  \n",
       "23            0.170779    0.009634  \n",
       "24            0.164873    0.009301  \n",
       "25            0.164303    0.009269  \n",
       "26            0.157196    0.008868  \n",
       "27            0.155013    0.008745  \n",
       "28            0.153558    0.008663  \n",
       "29            0.152865    0.008624  \n",
       "..                 ...         ...  \n",
       "74            0.082621    0.004661  \n",
       "75            0.071135    0.004013  \n",
       "76            0.068409    0.003859  \n",
       "77            0.064267    0.003626  \n",
       "78            0.057866    0.003264  \n",
       "79            0.056630    0.003195  \n",
       "80            0.056238    0.003173  \n",
       "81            0.051031    0.002879  \n",
       "82            0.048978    0.002763  \n",
       "83            0.048235    0.002721  \n",
       "84            0.045442    0.002564  \n",
       "85            0.042288    0.002386  \n",
       "86            0.041627    0.002348  \n",
       "87            0.040608    0.002291  \n",
       "88            0.036050    0.002034  \n",
       "89            0.031659    0.001786  \n",
       "90            0.030489    0.001720  \n",
       "91            0.024025    0.001355  \n",
       "92            0.021773    0.001228  \n",
       "93            0.013969    0.000788  \n",
       "94            0.011763    0.000664  \n",
       "95            0.009409    0.000531  \n",
       "96            0.009176    0.000518  \n",
       "97            0.008268    0.000466  \n",
       "98            0.007912    0.000446  \n",
       "99            0.006502    0.000367  \n",
       "100           0.005913    0.000334  \n",
       "101           0.005715    0.000322  \n",
       "102           0.001979    0.000112  \n",
       "103           0.000555    0.000031  \n",
       "\n",
       "[104 rows x 4 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varimp_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 'clm_den_flag'\n",
    "x1 = ['tin_denied_prcnt_grp_G60-100','bil_diff_fst_norm_log','diag_amnt_avg','icn','cpt_denied_prcnt_grp_G60-100','npi_denied_prcnt_grp_G40-70','npi_denied_prcnt_grp_G0-15','unit_agg_norm_log','npi_diag_amnt_avg','tin_diag_amnt_avg','clm_tot_chrg_amt_v2_norm_log','diag_denied_prcnt_grp_G0-15','collect_set_denied_prcnt_grp_G0-20','collect_set_denied_prcnt_grp_G50-100','tin_denied_prcnt_grp_G30-60','cpt_denied_prcnt_grp_G20-40','tin_denied_prcnt_grp_G05-20','npi_denied_prcnt_grp_G0','cpt_denied_prcnt_grp_G40-60','diag_denied_prcnt_grp_G75-100','cpt_denied_prcnt_grp_G05-10','lob_denied_prcnt_grp_G30-50','npi_denied_prcnt_grp_G15-40','lob_denied_prcnt_grp_G20-30','cpt_denied_prcnt_grp_Others','policy_denied_prcnt_grp_G30-50','mem_age_bin_(45.0, 60.0]','diag_denied_prcnt_grp_G30-55','mem_age_bin_(20.0, 45.0]','diag_denied_prcnt_grp_G55-75','policy_denied_prcnt_grp_Others','npi_denied_prcnt_grp_G90-100','cpt_denied_prcnt_grp_G10-20','bil_recv_month_3','plc_of_srvc_bin_others','npi_denied_prcnt_grp_G70-90','state_denied_prcnt_grp_G0-15','bil_recv_month_2','policy_denied_prcnt_grp_G0-20','diag_amnt_avg_ind_above','tin_diag_amnt_avg_ind_above','policy_denied_prcnt_grp_G20-30','npi_diag_amnt_avg_ind_above','npi_denied_prcnt_grp_Others','mem_age_bin_(60.0, 146.0]','bil_diff_fst_bin_(-17.0, 90.0]','tin_denied_prcnt_grp_Others','state_denied_prcnt_grp_G30-50','cpt_denied_prcnt_grp_G0-05','st_abbr_cd_bin_others','listed_presence','bil_recv_month_1','diag_denied_prcnt_grp_G15-25','state_denied_prcnt_grp_G25-30','bil_recv_month_5','plc_of_srvc_bin_22','plc_of_srvc_bin_11','bil_recv_month_11','diag_denied_prcnt_grp_Others','bil_recv_month_12','plc_of_srvc_bin_21','bil_recv_month_10','bil_recv_month_6','mem_age_bin_(0.0, 20.0]','bil_recv_month_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "gbm = H2OGradientBoostingEstimator(balance_classes=True, seed=1,ntrees =1000,stopping_rounds = 5, stopping_tolerance = 1e-4, stopping_metric = \"AUC\")\n",
    "gbm.train(x=x1, y=y, training_frame=train,validation_frame=valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.1550401605585432\n",
      "RMSE: 0.393751394357586\n",
      "LogLoss: 0.492331238666261\n",
      "Mean Per-Class Error: 0.22364476452912307\n",
      "AUC: 0.8393082073435791\n",
      "pr_auc: 0.7436855315875074\n",
      "Gini: 0.6786164146871583\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.25437779490288176: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>4041.0</td>\n",
       "<td>1106.0</td>\n",
       "<td>0.2149</td>\n",
       "<td> (1106.0/5147.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>644.0</td>\n",
       "<td>2127.0</td>\n",
       "<td>0.2324</td>\n",
       "<td> (644.0/2771.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>4685.0</td>\n",
       "<td>3233.0</td>\n",
       "<td>0.221</td>\n",
       "<td> (1750.0/7918.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0     1     Error    Rate\n",
       "-----  ----  ----  -------  ---------------\n",
       "0      4041  1106  0.2149   (1106.0/5147.0)\n",
       "1      644   2127  0.2324   (644.0/2771.0)\n",
       "Total  4685  3233  0.221    (1750.0/7918.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.2543778</td>\n",
       "<td>0.7085276</td>\n",
       "<td>254.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0768899</td>\n",
       "<td>0.7808464</td>\n",
       "<td>339.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5306252</td>\n",
       "<td>0.7077416</td>\n",
       "<td>161.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4267500</td>\n",
       "<td>0.7870674</td>\n",
       "<td>195.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9760047</td>\n",
       "<td>0.9855072</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0006082</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9908977</td>\n",
       "<td>0.9998057</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2974775</td>\n",
       "<td>0.5379851</td>\n",
       "<td>238.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2428731</td>\n",
       "<td>0.7754031</td>\n",
       "<td>259.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2543778</td>\n",
       "<td>0.7763552</td>\n",
       "<td>254.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.254378     0.708528  254\n",
       "max f2                       0.0768899    0.780846  339\n",
       "max f0point5                 0.530625     0.707742  161\n",
       "max accuracy                 0.42675      0.787067  195\n",
       "max precision                0.976005     0.985507  5\n",
       "max recall                   0.000608232  1         399\n",
       "max specificity              0.990898     0.999806  0\n",
       "max absolute_mcc             0.297477     0.537985  238\n",
       "max min_per_class_accuracy   0.242873     0.775403  259\n",
       "max mean_per_class_accuracy  0.254378     0.776355  254"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 35.00 %, avg score: 30.68 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0101036</td>\n",
       "<td>0.9735862</td>\n",
       "<td>2.8217340</td>\n",
       "<td>2.8217340</td>\n",
       "<td>0.9875</td>\n",
       "<td>0.9790234</td>\n",
       "<td>0.9875</td>\n",
       "<td>0.9790234</td>\n",
       "<td>0.0285096</td>\n",
       "<td>0.0285096</td>\n",
       "<td>182.1734031</td>\n",
       "<td>182.1734031</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200808</td>\n",
       "<td>0.9655477</td>\n",
       "<td>2.6766008</td>\n",
       "<td>2.7496238</td>\n",
       "<td>0.9367089</td>\n",
       "<td>0.9694880</td>\n",
       "<td>0.9622642</td>\n",
       "<td>0.9742857</td>\n",
       "<td>0.0267052</td>\n",
       "<td>0.0552147</td>\n",
       "<td>167.6600779</td>\n",
       "<td>174.9623799</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300581</td>\n",
       "<td>0.9489577</td>\n",
       "<td>2.4595791</td>\n",
       "<td>2.6533485</td>\n",
       "<td>0.8607595</td>\n",
       "<td>0.9581435</td>\n",
       "<td>0.9285714</td>\n",
       "<td>0.9689276</td>\n",
       "<td>0.0245399</td>\n",
       "<td>0.0797546</td>\n",
       "<td>145.9579095</td>\n",
       "<td>165.3348456</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400354</td>\n",
       "<td>0.9203419</td>\n",
       "<td>2.5680899</td>\n",
       "<td>2.6321011</td>\n",
       "<td>0.8987342</td>\n",
       "<td>0.9363037</td>\n",
       "<td>0.9211356</td>\n",
       "<td>0.9607973</td>\n",
       "<td>0.0256225</td>\n",
       "<td>0.1053771</td>\n",
       "<td>156.8089937</td>\n",
       "<td>163.2101065</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0502652</td>\n",
       "<td>0.9002364</td>\n",
       "<td>2.4694031</td>\n",
       "<td>2.5989892</td>\n",
       "<td>0.8641975</td>\n",
       "<td>0.9091611</td>\n",
       "<td>0.9095477</td>\n",
       "<td>0.9502884</td>\n",
       "<td>0.0252616</td>\n",
       "<td>0.1306388</td>\n",
       "<td>146.9403121</td>\n",
       "<td>159.8989172</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1002778</td>\n",
       "<td>0.8569061</td>\n",
       "<td>2.3234838</td>\n",
       "<td>2.4615835</td>\n",
       "<td>0.8131313</td>\n",
       "<td>0.8773984</td>\n",
       "<td>0.8614610</td>\n",
       "<td>0.9139352</td>\n",
       "<td>0.1162035</td>\n",
       "<td>0.2468423</td>\n",
       "<td>132.3483846</td>\n",
       "<td>146.1583493</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500379</td>\n",
       "<td>0.7807316</td>\n",
       "<td>2.0161718</td>\n",
       "<td>2.3138628</td>\n",
       "<td>0.7055838</td>\n",
       "<td>0.8251655</td>\n",
       "<td>0.8097643</td>\n",
       "<td>0.8844948</td>\n",
       "<td>0.1003248</td>\n",
       "<td>0.3471671</td>\n",
       "<td>101.6171845</td>\n",
       "<td>131.3862795</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000505</td>\n",
       "<td>0.6587881</td>\n",
       "<td>2.0132049</td>\n",
       "<td>2.2386983</td>\n",
       "<td>0.7045455</td>\n",
       "<td>0.7232034</td>\n",
       "<td>0.7834596</td>\n",
       "<td>0.8441719</td>\n",
       "<td>0.1006857</td>\n",
       "<td>0.4478528</td>\n",
       "<td>101.3204947</td>\n",
       "<td>123.8698333</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3002021</td>\n",
       "<td>0.4423589</td>\n",
       "<td>1.7476221</td>\n",
       "<td>2.0748685</td>\n",
       "<td>0.6116015</td>\n",
       "<td>0.5438295</td>\n",
       "<td>0.7261254</td>\n",
       "<td>0.7439736</td>\n",
       "<td>0.1750271</td>\n",
       "<td>0.6228798</td>\n",
       "<td>74.7622079</td>\n",
       "<td>107.4868518</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.3999747</td>\n",
       "<td>0.2673499</td>\n",
       "<td>1.3491515</td>\n",
       "<td>1.8938403</td>\n",
       "<td>0.4721519</td>\n",
       "<td>0.3512108</td>\n",
       "<td>0.6627723</td>\n",
       "<td>0.6459999</td>\n",
       "<td>0.1346084</td>\n",
       "<td>0.7574883</td>\n",
       "<td>34.9151474</td>\n",
       "<td>89.3840269</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.1581574</td>\n",
       "<td>0.8009525</td>\n",
       "<td>1.6752075</td>\n",
       "<td>0.2803030</td>\n",
       "<td>0.2053481</td>\n",
       "<td>0.5862592</td>\n",
       "<td>0.5578473</td>\n",
       "<td>0.0801155</td>\n",
       "<td>0.8376038</td>\n",
       "<td>-19.9047494</td>\n",
       "<td>67.5207506</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000253</td>\n",
       "<td>0.0972240</td>\n",
       "<td>0.5195368</td>\n",
       "<td>1.4825552</td>\n",
       "<td>0.1818182</td>\n",
       "<td>0.1242439</td>\n",
       "<td>0.5188381</td>\n",
       "<td>0.4855648</td>\n",
       "<td>0.0519668</td>\n",
       "<td>0.8895706</td>\n",
       "<td>-48.0463239</td>\n",
       "<td>48.2555174</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999242</td>\n",
       "<td>0.0593018</td>\n",
       "<td>0.4371071</td>\n",
       "<td>1.3333402</td>\n",
       "<td>0.1529709</td>\n",
       "<td>0.0773842</td>\n",
       "<td>0.4666185</td>\n",
       "<td>0.4273059</td>\n",
       "<td>0.0436665</td>\n",
       "<td>0.9332371</td>\n",
       "<td>-56.2892902</td>\n",
       "<td>33.3340192</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999495</td>\n",
       "<td>0.0342388</td>\n",
       "<td>0.3174947</td>\n",
       "<td>1.2063194</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.0468224</td>\n",
       "<td>0.4221661</td>\n",
       "<td>0.3797305</td>\n",
       "<td>0.0317575</td>\n",
       "<td>0.9649946</td>\n",
       "<td>-68.2505313</td>\n",
       "<td>20.6319409</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999747</td>\n",
       "<td>0.0139767</td>\n",
       "<td>0.2092579</td>\n",
       "<td>1.0955037</td>\n",
       "<td>0.0732323</td>\n",
       "<td>0.0239543</td>\n",
       "<td>0.3833848</td>\n",
       "<td>0.3401887</td>\n",
       "<td>0.0209311</td>\n",
       "<td>0.9859257</td>\n",
       "<td>-79.0742138</td>\n",
       "<td>9.5503700</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001229</td>\n",
       "<td>0.1407079</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0492424</td>\n",
       "<td>0.0058931</td>\n",
       "<td>0.3499621</td>\n",
       "<td>0.3067507</td>\n",
       "<td>0.0140743</td>\n",
       "<td>1.0</td>\n",
       "<td>-85.9292127</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0101036                   0.973586           2.82173   2.82173            0.9875           0.979023    0.9875                      0.979023            0.0285096       0.0285096                  182.173   182.173\n",
       "    2        0.0200808                   0.965548           2.6766    2.74962            0.936709         0.969488    0.962264                    0.974286            0.0267052       0.0552147                  167.66    174.962\n",
       "    3        0.0300581                   0.948958           2.45958   2.65335            0.860759         0.958144    0.928571                    0.968928            0.0245399       0.0797546                  145.958   165.335\n",
       "    4        0.0400354                   0.920342           2.56809   2.6321             0.898734         0.936304    0.921136                    0.960797            0.0256225       0.105377                   156.809   163.21\n",
       "    5        0.0502652                   0.900236           2.4694    2.59899            0.864198         0.909161    0.909548                    0.950288            0.0252616       0.130639                   146.94    159.899\n",
       "    6        0.100278                    0.856906           2.32348   2.46158            0.813131         0.877398    0.861461                    0.913935            0.116204        0.246842                   132.348   146.158\n",
       "    7        0.150038                    0.780732           2.01617   2.31386            0.705584         0.825166    0.809764                    0.884495            0.100325        0.347167                   101.617   131.386\n",
       "    8        0.200051                    0.658788           2.0132    2.2387             0.704545         0.723203    0.78346                     0.844172            0.100686        0.447853                   101.32    123.87\n",
       "    9        0.300202                    0.442359           1.74762   2.07487            0.611602         0.54383     0.726125                    0.743974            0.175027        0.62288                    74.7622   107.487\n",
       "    10       0.399975                    0.26735            1.34915   1.89384            0.472152         0.351211    0.662772                    0.646               0.134608        0.757488                   34.9151   89.384\n",
       "    11       0.5                         0.158157           0.800953  1.67521            0.280303         0.205348    0.586259                    0.557847            0.0801155       0.837604                   -19.9047  67.5208\n",
       "    12       0.600025                    0.097224           0.519537  1.48256            0.181818         0.124244    0.518838                    0.485565            0.0519668       0.889571                   -48.0463  48.2555\n",
       "    13       0.699924                    0.0593018          0.437107  1.33334            0.152971         0.0773842   0.466619                    0.427306            0.0436665       0.933237                   -56.2893  33.334\n",
       "    14       0.799949                    0.0342388          0.317495  1.20632            0.111111         0.0468224   0.422166                    0.37973             0.0317575       0.964995                   -68.2505  20.6319\n",
       "    15       0.899975                    0.0139767          0.209258  1.0955             0.0732323        0.0239543   0.383385                    0.340189            0.0209311       0.985926                   -79.0742  9.55037\n",
       "    16       1                           0.00012295         0.140708  1                  0.0492424        0.00589311  0.349962                    0.306751            0.0140743       1                          -85.9292  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbm_perf = gbm.model_performance(test_hex)\n",
    "print(gbm_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.grid.grid_search import H2OGridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "gbm_params2 = {'learn_rate': [i * 0.01 for i in range(1, 11)],\n",
    "                'max_depth': list(range(2, 20,2)),\n",
    "                'sample_rate': [i * 0.1 for i in range(5, 11)],\n",
    "                'col_sample_rate': [i * 0.1 for i in range(5, 11)]}\n",
    "\n",
    "# Search criteria\n",
    "search_criteria = {'strategy': 'RandomDiscrete', 'max_models': 50, 'seed': 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_grid2 = H2OGridSearch(model=H2OGradientBoostingEstimator(balance_classes=True),\n",
    "                          grid_id='gbm_grid',\n",
    "                          hyper_params=gbm_params2,\n",
    "                          search_criteria=search_criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Grid Build progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_grid2.train(x=x, y=y,\n",
    "                training_frame=train,\n",
    "                validation_frame=valid,\n",
    "                ntrees=700,\n",
    "                seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         col_sample_rate learn_rate max_depth         sample_rate  \\\n",
      "0                    0.9        0.1        14                 1.0   \n",
      "1                    0.5       0.08        16  0.6000000000000001   \n",
      "2                    0.8       0.06        12  0.7000000000000001   \n",
      "3                    0.5       0.07        12  0.7000000000000001   \n",
      "4     0.6000000000000001       0.09        18  0.7000000000000001   \n",
      "5                    1.0       0.04        12                 0.8   \n",
      "6                    0.9       0.07        16  0.6000000000000001   \n",
      "7                    0.9        0.1        18  0.6000000000000001   \n",
      "8     0.6000000000000001       0.08        12  0.7000000000000001   \n",
      "9     0.7000000000000001       0.01        12  0.7000000000000001   \n",
      "10                   0.8       0.06        12                 0.8   \n",
      "11    0.7000000000000001        0.1        14  0.7000000000000001   \n",
      "12                   0.8       0.04         6                 1.0   \n",
      "13                   0.5       0.04        14                 1.0   \n",
      "14                   0.9       0.03        10  0.6000000000000001   \n",
      "15    0.7000000000000001       0.09        16                 1.0   \n",
      "16                   0.9       0.09         6                 0.8   \n",
      "17                   0.8       0.04         4  0.6000000000000001   \n",
      "18                   0.5       0.04        12                 1.0   \n",
      "19    0.7000000000000001       0.03         2                 1.0   \n",
      "20    0.6000000000000001        0.1        14                 1.0   \n",
      "21                   0.9       0.08        10                 0.8   \n",
      "22    0.7000000000000001        0.1         8  0.7000000000000001   \n",
      "23    0.7000000000000001       0.02        10                 0.5   \n",
      "24                   0.9       0.01        10  0.6000000000000001   \n",
      "25                   1.0       0.07         6  0.7000000000000001   \n",
      "26                   0.8        0.1         4                 0.8   \n",
      "27    0.6000000000000001       0.08         6                 1.0   \n",
      "28                   1.0       0.09        18                 0.9   \n",
      "29                   0.5       0.08         2                 0.5   \n",
      "30                   1.0        0.1        12                 0.5   \n",
      "31    0.7000000000000001       0.04         6                 0.5   \n",
      "32                   0.9       0.09         4                 0.9   \n",
      "33                   1.0       0.04        16                 0.5   \n",
      "34                   0.8       0.03        12                 1.0   \n",
      "35    0.6000000000000001       0.09        10                 1.0   \n",
      "36                   0.8       0.05         6                 0.9   \n",
      "37                   0.5       0.03         8                 0.9   \n",
      "38                   0.5       0.09        18                 0.5   \n",
      "39                   1.0       0.09         8                 0.5   \n",
      "40                   0.8        0.1        14  0.6000000000000001   \n",
      "41                   1.0       0.08        18                 0.9   \n",
      "42    0.7000000000000001       0.06         4                 0.8   \n",
      "43    0.7000000000000001       0.06        14                 0.9   \n",
      "44                   0.5       0.08         8                 0.8   \n",
      "45                   0.8       0.07         6                 0.5   \n",
      "46                   1.0       0.09        10                 1.0   \n",
      "47    0.6000000000000001       0.04         2                 0.9   \n",
      "48                   0.8       0.01        18                 1.0   \n",
      "49                   0.5        0.1         4  0.7000000000000001   \n",
      "\n",
      "            model_ids              recall  \n",
      "0   gbm_grid_model_24  0.7410433689503457  \n",
      "1   gbm_grid_model_13  0.7366436203645506  \n",
      "2   gbm_grid_model_26   0.735700817096166  \n",
      "3   gbm_grid_model_29  0.7353865493400377  \n",
      "4   gbm_grid_model_12  0.7350722815839095  \n",
      "5   gbm_grid_model_19  0.7350722815839095  \n",
      "6   gbm_grid_model_50  0.7300439974858579  \n",
      "7   gbm_grid_model_49  0.7256442489000628  \n",
      "8   gbm_grid_model_39  0.7193588937774984  \n",
      "9   gbm_grid_model_25  0.7193588937774984  \n",
      "10  gbm_grid_model_17   0.718730358265242  \n",
      "11   gbm_grid_model_6   0.718730358265242  \n",
      "12  gbm_grid_model_31  0.7181018227529855  \n",
      "13  gbm_grid_model_20  0.7181018227529855  \n",
      "14  gbm_grid_model_41  0.7174732872407291  \n",
      "15  gbm_grid_model_30  0.7168447517284726  \n",
      "16  gbm_grid_model_23  0.7152734129478315  \n",
      "17  gbm_grid_model_40  0.7149591451917033  \n",
      "18  gbm_grid_model_21  0.7143306096794468  \n",
      "19  gbm_grid_model_37  0.7127592708988058  \n",
      "20  gbm_grid_model_33  0.7118164676304212  \n",
      "21   gbm_grid_model_2  0.7099308610936518  \n",
      "22  gbm_grid_model_36  0.7096165933375236  \n",
      "23  gbm_grid_model_18  0.7083595223130107  \n",
      "24   gbm_grid_model_9  0.7071024512884978  \n",
      "25  gbm_grid_model_46  0.7067881835323696  \n",
      "26  gbm_grid_model_11  0.7064739157762414  \n",
      "27  gbm_grid_model_44  0.7061596480201131  \n",
      "28  gbm_grid_model_14  0.7042740414833438  \n",
      "29   gbm_grid_model_1  0.7039597737272156  \n",
      "30  gbm_grid_model_42  0.7027027027027027  \n",
      "31  gbm_grid_model_27  0.7023884349465744  \n",
      "32   gbm_grid_model_7  0.7005028284098052  \n",
      "33   gbm_grid_model_5  0.6983029541169076  \n",
      "34  gbm_grid_model_15   0.697360150848523  \n",
      "35   gbm_grid_model_8  0.6964173475801383  \n",
      "36  gbm_grid_model_16  0.6961030798240101  \n",
      "37  gbm_grid_model_34  0.6957888120678818  \n",
      "38  gbm_grid_model_22  0.6932746700188561  \n",
      "39  gbm_grid_model_10  0.6926461345065996  \n",
      "40  gbm_grid_model_32  0.6923318667504714  \n",
      "41  gbm_grid_model_35  0.6907605279698303  \n",
      "42   gbm_grid_model_3  0.6891891891891891  \n",
      "43  gbm_grid_model_43   0.688874921433061  \n",
      "44  gbm_grid_model_48  0.6838466373350094  \n",
      "45  gbm_grid_model_45   0.683218101822753  \n",
      "46  gbm_grid_model_47  0.6810182275298554  \n",
      "47  gbm_grid_model_28   0.680389692017599  \n",
      "48  gbm_grid_model_38  0.6800754242614707  \n",
      "49   gbm_grid_model_4   0.677561282212445  \n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_gridperf2 = gbm_grid2.get_grid(sort_by='recall', decreasing=True)\n",
    "gbm_gridperf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gbm2 = gbm_gridperf2.models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.17500071999540193\n",
      "RMSE: 0.41833087382525563\n",
      "LogLoss: 0.6704441759805344\n",
      "Mean Per-Class Error: 0.22973861156134512\n",
      "AUC: 0.8387157027631585\n",
      "pr_auc: 0.7230127704249386\n",
      "Gini: 0.6774314055263171\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.11608699873730782: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>4073.0</td>\n",
       "<td>1074.0</td>\n",
       "<td>0.2087</td>\n",
       "<td> (1074.0/5147.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>695.0</td>\n",
       "<td>2076.0</td>\n",
       "<td>0.2508</td>\n",
       "<td> (695.0/2771.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>4768.0</td>\n",
       "<td>3150.0</td>\n",
       "<td>0.2234</td>\n",
       "<td> (1769.0/7918.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0     1     Error    Rate\n",
       "-----  ----  ----  -------  ---------------\n",
       "0      4073  1074  0.2087   (1074.0/5147.0)\n",
       "1      695   2076  0.2508   (695.0/2771.0)\n",
       "Total  4768  3150  0.2234   (1769.0/7918.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1160870</td>\n",
       "<td>0.7012329</td>\n",
       "<td>309.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0089068</td>\n",
       "<td>0.7854348</td>\n",
       "<td>381.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3620474</td>\n",
       "<td>0.7026477</td>\n",
       "<td>222.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3620474</td>\n",
       "<td>0.7856782</td>\n",
       "<td>222.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9989959</td>\n",
       "<td>0.9821429</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0002013</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9989959</td>\n",
       "<td>0.9998057</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.1710081</td>\n",
       "<td>0.5299429</td>\n",
       "<td>286.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0929851</td>\n",
       "<td>0.7672431</td>\n",
       "<td>320.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1160870</td>\n",
       "<td>0.7702614</td>\n",
       "<td>309.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.116087     0.701233  309\n",
       "max f2                       0.00890676   0.785435  381\n",
       "max f0point5                 0.362047     0.702648  222\n",
       "max accuracy                 0.362047     0.785678  222\n",
       "max precision                0.998996     0.982143  0\n",
       "max recall                   0.000201281  1         399\n",
       "max specificity              0.998996     0.999806  0\n",
       "max absolute_mcc             0.171008     0.529943  286\n",
       "max min_per_class_accuracy   0.0929851    0.767243  320\n",
       "max mean_per_class_accuracy  0.116087     0.770261  309"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 35.00 %, avg score: 27.76 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0101036</td>\n",
       "<td>0.9983001</td>\n",
       "<td>2.7502977</td>\n",
       "<td>2.7502977</td>\n",
       "<td>0.9625</td>\n",
       "<td>0.9988602</td>\n",
       "<td>0.9625</td>\n",
       "<td>0.9988602</td>\n",
       "<td>0.0277878</td>\n",
       "<td>0.0277878</td>\n",
       "<td>175.0297726</td>\n",
       "<td>175.0297726</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200808</td>\n",
       "<td>0.9970888</td>\n",
       "<td>2.6404305</td>\n",
       "<td>2.6957096</td>\n",
       "<td>0.9240506</td>\n",
       "<td>0.9977093</td>\n",
       "<td>0.9433962</td>\n",
       "<td>0.9982884</td>\n",
       "<td>0.0263443</td>\n",
       "<td>0.0541321</td>\n",
       "<td>164.0430499</td>\n",
       "<td>169.5709607</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300581</td>\n",
       "<td>0.9960115</td>\n",
       "<td>2.3510683</td>\n",
       "<td>2.5813118</td>\n",
       "<td>0.8227848</td>\n",
       "<td>0.9965984</td>\n",
       "<td>0.9033613</td>\n",
       "<td>0.9977274</td>\n",
       "<td>0.0234572</td>\n",
       "<td>0.0775893</td>\n",
       "<td>135.1068252</td>\n",
       "<td>158.1311846</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400354</td>\n",
       "<td>0.9944510</td>\n",
       "<td>2.5319197</td>\n",
       "<td>2.5690028</td>\n",
       "<td>0.8860759</td>\n",
       "<td>0.9952978</td>\n",
       "<td>0.8990536</td>\n",
       "<td>0.9971219</td>\n",
       "<td>0.0252616</td>\n",
       "<td>0.1028510</td>\n",
       "<td>153.1919656</td>\n",
       "<td>156.9002752</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500126</td>\n",
       "<td>0.9917373</td>\n",
       "<td>2.4957494</td>\n",
       "<td>2.5543891</td>\n",
       "<td>0.8734177</td>\n",
       "<td>0.9931864</td>\n",
       "<td>0.8939394</td>\n",
       "<td>0.9963368</td>\n",
       "<td>0.0249008</td>\n",
       "<td>0.1277517</td>\n",
       "<td>149.5749375</td>\n",
       "<td>155.4389073</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000253</td>\n",
       "<td>0.9723308</td>\n",
       "<td>2.3306996</td>\n",
       "<td>2.4425444</td>\n",
       "<td>0.8156566</td>\n",
       "<td>0.9836871</td>\n",
       "<td>0.8547980</td>\n",
       "<td>0.9900120</td>\n",
       "<td>0.1165644</td>\n",
       "<td>0.2443161</td>\n",
       "<td>133.0699634</td>\n",
       "<td>144.2544354</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500379</td>\n",
       "<td>0.9177713</td>\n",
       "<td>2.1935997</td>\n",
       "<td>2.3595628</td>\n",
       "<td>0.7676768</td>\n",
       "<td>0.9506362</td>\n",
       "<td>0.8257576</td>\n",
       "<td>0.9768867</td>\n",
       "<td>0.1097077</td>\n",
       "<td>0.3540238</td>\n",
       "<td>119.3599656</td>\n",
       "<td>135.9562788</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2005557</td>\n",
       "<td>0.7630435</td>\n",
       "<td>1.9216366</td>\n",
       "<td>2.2492539</td>\n",
       "<td>0.6725</td>\n",
       "<td>0.8462242</td>\n",
       "<td>0.7871537</td>\n",
       "<td>0.9439743</td>\n",
       "<td>0.0970769</td>\n",
       "<td>0.4511007</td>\n",
       "<td>92.1636593</td>\n",
       "<td>124.9253923</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000758</td>\n",
       "<td>0.3601150</td>\n",
       "<td>1.7188228</td>\n",
       "<td>2.0733365</td>\n",
       "<td>0.6015228</td>\n",
       "<td>0.5624900</td>\n",
       "<td>0.7255892</td>\n",
       "<td>0.8174551</td>\n",
       "<td>0.1710574</td>\n",
       "<td>0.6221581</td>\n",
       "<td>71.8822760</td>\n",
       "<td>107.3336517</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.3999747</td>\n",
       "<td>0.1129349</td>\n",
       "<td>1.2860341</td>\n",
       "<td>1.8766974</td>\n",
       "<td>0.4500632</td>\n",
       "<td>0.2121614</td>\n",
       "<td>0.6567730</td>\n",
       "<td>0.6662750</td>\n",
       "<td>0.1284735</td>\n",
       "<td>0.7506315</td>\n",
       "<td>28.6034105</td>\n",
       "<td>87.6697361</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0399819</td>\n",
       "<td>0.8189920</td>\n",
       "<td>1.6651029</td>\n",
       "<td>0.2866162</td>\n",
       "<td>0.0695605</td>\n",
       "<td>0.5827229</td>\n",
       "<td>0.5469019</td>\n",
       "<td>0.0819199</td>\n",
       "<td>0.8325514</td>\n",
       "<td>-18.1008023</td>\n",
       "<td>66.5102851</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000253</td>\n",
       "<td>0.0152406</td>\n",
       "<td>0.5880867</td>\n",
       "<td>1.4855624</td>\n",
       "<td>0.2058081</td>\n",
       "<td>0.0254612</td>\n",
       "<td>0.5198905</td>\n",
       "<td>0.4599769</td>\n",
       "<td>0.0588235</td>\n",
       "<td>0.8913750</td>\n",
       "<td>-41.1913250</td>\n",
       "<td>48.5562385</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999242</td>\n",
       "<td>0.0060589</td>\n",
       "<td>0.4623943</td>\n",
       "<td>1.3395274</td>\n",
       "<td>0.1618205</td>\n",
       "<td>0.0100868</td>\n",
       "<td>0.4687838</td>\n",
       "<td>0.3957648</td>\n",
       "<td>0.0461927</td>\n",
       "<td>0.9375677</td>\n",
       "<td>-53.7605715</td>\n",
       "<td>33.9527386</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999495</td>\n",
       "<td>0.0023429</td>\n",
       "<td>0.2742000</td>\n",
       "<td>1.2063194</td>\n",
       "<td>0.0959596</td>\n",
       "<td>0.0040172</td>\n",
       "<td>0.4221661</td>\n",
       "<td>0.3467809</td>\n",
       "<td>0.0274269</td>\n",
       "<td>0.9649946</td>\n",
       "<td>-72.5800043</td>\n",
       "<td>20.6319409</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999747</td>\n",
       "<td>0.0008021</td>\n",
       "<td>0.2092579</td>\n",
       "<td>1.0955037</td>\n",
       "<td>0.0732323</td>\n",
       "<td>0.0014996</td>\n",
       "<td>0.3833848</td>\n",
       "<td>0.3084056</td>\n",
       "<td>0.0209311</td>\n",
       "<td>0.9859257</td>\n",
       "<td>-79.0742138</td>\n",
       "<td>9.5503700</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000327</td>\n",
       "<td>0.1407079</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0492424</td>\n",
       "<td>0.0003968</td>\n",
       "<td>0.3499621</td>\n",
       "<td>0.2775969</td>\n",
       "<td>0.0140743</td>\n",
       "<td>1.0</td>\n",
       "<td>-85.9292127</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0101036                   0.9983             2.7503    2.7503             0.9625           0.99886      0.9625                      0.99886             0.0277878       0.0277878                  175.03    175.03\n",
       "    2        0.0200808                   0.997089           2.64043   2.69571            0.924051         0.997709     0.943396                    0.998288            0.0263443       0.0541321                  164.043   169.571\n",
       "    3        0.0300581                   0.996011           2.35107   2.58131            0.822785         0.996598     0.903361                    0.997727            0.0234572       0.0775893                  135.107   158.131\n",
       "    4        0.0400354                   0.994451           2.53192   2.569              0.886076         0.995298     0.899054                    0.997122            0.0252616       0.102851                   153.192   156.9\n",
       "    5        0.0500126                   0.991737           2.49575   2.55439            0.873418         0.993186     0.893939                    0.996337            0.0249008       0.127752                   149.575   155.439\n",
       "    6        0.100025                    0.972331           2.3307    2.44254            0.815657         0.983687     0.854798                    0.990012            0.116564        0.244316                   133.07    144.254\n",
       "    7        0.150038                    0.917771           2.1936    2.35956            0.767677         0.950636     0.825758                    0.976887            0.109708        0.354024                   119.36    135.956\n",
       "    8        0.200556                    0.763043           1.92164   2.24925            0.6725           0.846224     0.787154                    0.943974            0.0970769       0.451101                   92.1637   124.925\n",
       "    9        0.300076                    0.360115           1.71882   2.07334            0.601523         0.56249      0.725589                    0.817455            0.171057        0.622158                   71.8823   107.334\n",
       "    10       0.399975                    0.112935           1.28603   1.8767             0.450063         0.212161     0.656773                    0.666275            0.128473        0.750632                   28.6034   87.6697\n",
       "    11       0.5                         0.0399819          0.818992  1.6651             0.286616         0.0695605    0.582723                    0.546902            0.0819199       0.832551                   -18.1008  66.5103\n",
       "    12       0.600025                    0.0152406          0.588087  1.48556            0.205808         0.0254612    0.519891                    0.459977            0.0588235       0.891375                   -41.1913  48.5562\n",
       "    13       0.699924                    0.00605892         0.462394  1.33953            0.16182          0.0100868    0.468784                    0.395765            0.0461927       0.937568                   -53.7606  33.9527\n",
       "    14       0.799949                    0.0023429          0.2742    1.20632            0.0959596        0.00401718   0.422166                    0.346781            0.0274269       0.964995                   -72.58    20.6319\n",
       "    15       0.899975                    0.000802121        0.209258  1.0955             0.0732323        0.00149964   0.383385                    0.308406            0.0209311       0.985926                   -79.0742  9.55037\n",
       "    16       1                           3.27076e-05        0.140708  1                  0.0492424        0.000396806  0.349962                    0.277597            0.0140743       1                          -85.9292  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gbm2_perf2 = best_gbm2.model_performance(test_hex)\n",
    "best_gbm2_perf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
